{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.cluster\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from skrules import SkopeRules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train =  pd.read_csv('./archive/train.csv')\n",
    "df_test = pd.read_csv('./archive/test.csv')\n",
    "\n",
    "df_train.income = df_train.income.map({'<=50K':0, '>50K':1})\n",
    "df_test.income = df_test.income.map({'<=50K':0, '>50K':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = sklearn.preprocessing.LabelEncoder()\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].dtype == 'object':\n",
    "        le.fit(df_train[col])\n",
    "        df_train[col] = le.transform(df_train[col])\n",
    "        df_test[col] = le.transform(df_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 39\n",
    "exp_iter = 10\n",
    "random.seed(random_state)\n",
    "\n",
    "#Get datasets\n",
    "X_train = df_train.drop('income', axis=1)\n",
    "y_train = df_train.income\n",
    "X_test = df_test.drop('income', axis=1)\n",
    "y_test = df_test.income\n",
    "test_x = X_test.values\n",
    "n_classes = len(np.unique(y_train))\n",
    "feat_list = [each.replace(' ','_') for each in X_train.columns]\n",
    "X = np.vstack((X_train.values, test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SkopeRules(max_depth_duplication=2,\n",
    "                    n_estimators=100,\n",
    "                    precision_min=0.3,\n",
    "                    recall_min=0.1,\n",
    "                    feature_names=feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SkopeRules(feature_names=['age', 'workclass', 'fnlwgt', 'education',\n",
       "                          'education-num', 'marital-status', 'occupation',\n",
       "                          'relationship', 'race', 'sex', 'capital-gain',\n",
       "                          'capital-loss', 'hours-per-week', 'native-country'],\n",
       "           max_depth_duplication=2, n_estimators=100, precision_min=0.3,\n",
       "           recall_min=0.1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_rules1 = clf.score_top_rules(test_x[:100])\n",
    "top_rules2 = clf.score_top_rules(test_x[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_identity_rules(top_rules1, top_rules2):\n",
    "    dis = np.array([np.array_equal(top_rules1[i],top_rules2[i]) for i in range(len(top_rules1))])\n",
    "    total = dis.shape[0]\n",
    "    true = np.sum(dis)\n",
    "    score = (total-true)/total\n",
    "    return score*100, true, total\n",
    "\n",
    "def calc_separability_rules(top_rules):\n",
    "    wrong = 0\n",
    "    for i in range(top_rules.shape[0]):\n",
    "        for j in range(top_rules.shape[0]):\n",
    "            if i == j:\n",
    "                continue\n",
    "            eq = np.array_equal(top_rules[i],top_rules[j])\n",
    "            if eq:\n",
    "                wrong = wrong + 1\n",
    "    total = top_rules.shape[0]\n",
    "    score = 100*abs(wrong)/total**2\n",
    "    return wrong,total,total**2,score\n",
    "\n",
    "def exp_enc(exp, feature_num):\n",
    "    enc_exp = np.zeros((len(exp),feature_num))\n",
    "    for i in range(len(exp)):\n",
    "        enc_exp[i][int(exp[i])] = 1\n",
    "    return enc_exp\n",
    "\n",
    "def calc_stability_rules(top_rules, labels):\n",
    "    total = labels.shape[0]\n",
    "    label_values = np.unique(labels)\n",
    "    n_clusters = label_values.shape[0]\n",
    "    init = np.array([[np.average(top_rules[np.where(labels == i)], axis = 0)] for i in label_values]).squeeze()\n",
    "    ct = sklearn.cluster.KMeans(n_clusters = n_clusters, random_state=1, n_init=10, init = init)\n",
    "    ct.fit(top_rules)\n",
    "    error = np.sum(np.abs(labels-ct.labels_))\n",
    "    if error/total > 0.5:\n",
    "        error = total-error\n",
    "    return error, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 100, 100)\n",
      "(4806, 100, 10000, 48.06)\n",
      "(36, 100)\n"
     ]
    }
   ],
   "source": [
    "i = calc_identity_rules(top_rules1, top_rules2)\n",
    "print(i)\n",
    "\n",
    "s = calc_separability_rules(top_rules1)\n",
    "print(s)\n",
    "\n",
    "enc_rules = exp_enc(top_rules1, int(max(top_rules1))+1)\n",
    "sb = calc_stability_rules(enc_rules, y_test[:100])\n",
    "print(sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_test(X_train, X_test):\n",
    "    X_test_norm = X_test.copy()\n",
    "    for i in X_train.columns:\n",
    "        scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "        scaler.fit(X_train[i].values.reshape(-1,1))\n",
    "        X_test_norm[i] = scaler.transform(X_test[i].values.reshape(-1,1))\n",
    "\n",
    "    return X_test_norm\n",
    "\n",
    "def calc_similarity(exp, X_test_norm):\n",
    "    dbscan = sklearn.cluster.DBSCAN(eps=0.5, min_samples=10)\n",
    "    dbscan.fit(X_test_norm[:400])\n",
    "    labels = dbscan.labels_\n",
    "    mean_dist = []\n",
    "    for i in np.unique(labels):\n",
    "        mean_dist.append(np.mean(sklearn.metrics.pairwise_distances(exp[np.where(labels == i), :].squeeze(), metric='euclidean')))\n",
    "    return np.min(mean_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34677520724698857\n"
     ]
    }
   ],
   "source": [
    "X_test_norm = normalize_test(X_train, X_test)\n",
    "sim = calc_similarity(enc_rules, X_test_norm[:100])\n",
    "\n",
    "print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
