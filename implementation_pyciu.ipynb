{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Jd_c3lzIKmtZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import sklearn.cluster\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import random\n",
        "from ciu import determine_ciu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WxVSqoTQSo8O"
      },
      "outputs": [],
      "source": [
        "df_train =  pd.read_csv('./archive/train.csv')\n",
        "df_test = pd.read_csv('./archive/test.csv')\n",
        "\n",
        "df_train.income = df_train.income.map({'<=50K':0, '>50K':1})\n",
        "df_test.income = df_test.income.map({'<=50K':0, '>50K':1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "49yhEpqST6h5"
      },
      "outputs": [],
      "source": [
        "le = sklearn.preprocessing.LabelEncoder()\n",
        "for col in df_train.columns:\n",
        "    if df_train[col].dtype == 'object':\n",
        "        le.fit(df_train[col])\n",
        "        df_train[col] = le.transform(df_train[col])\n",
        "        df_test[col] = le.transform(df_test[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "j3nd0QzLT7mO"
      },
      "outputs": [],
      "source": [
        "random_state = 39\n",
        "exp_iter = 10\n",
        "random.seed(random_state)\n",
        "\n",
        "#Get datasets\n",
        "X_train = df_train.drop('income', axis=1)\n",
        "y_train = df_train.income\n",
        "X_test = df_test.drop('income', axis=1)\n",
        "y_test = df_test.income\n",
        "test_x = X_test.values\n",
        "n_classes = len(np.unique(y_train))\n",
        "feat_list = [each.replace(' ','_') for each in X_train.columns]\n",
        "X = np.vstack((X_train.values, test_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "vfLLnPHrT8rR",
        "outputId": "02249ee6-4113-4ecc-b55a-16305ae672e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nIbymIaDUEWq"
      },
      "outputs": [],
      "source": [
        "income_ciu = determine_ciu(\n",
        "    X_test.iloc[10:11],\n",
        "    model.predict_proba,\n",
        "    X_train.to_dict('list'),\n",
        "    samples = 1000,\n",
        "    prediction_index = 1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U_qVbXRXE2d",
        "outputId": "0fd5ba67-2835-40a9-e7c3-2af56d62c35c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(income_ciu.ci)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WwK0_-cEXGtA"
      },
      "outputs": [],
      "source": [
        "def exp_fn_blk(xtest):\n",
        "    exp1 = []\n",
        "    for i in range(len(xtest)):\n",
        "        exp = determine_ciu(X_test.iloc[i:i+1], model.predict_proba, X_train.to_dict('list'), samples = 1000, prediction_index = 1)\n",
        "        exp_list = [[feat_list.index(i), exp.ci[i]] for i in exp.ci]\n",
        "        exp1.append(exp_list)\n",
        "    return np.array(exp1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vaz3eu--andi"
      },
      "outputs": [],
      "source": [
        "exp1 = exp_fn_blk(X_test[:100])\n",
        "exp2 = exp_fn_blk(X_test[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "l-YP1yaQawnj"
      },
      "outputs": [],
      "source": [
        "def calc_identity(exp1, exp2):\n",
        "    dis = np.array([np.array_equal(exp1[i],exp2[i]) for i in range(len(exp1))])\n",
        "    total = dis.shape[0]\n",
        "    true = np.sum(dis)\n",
        "    score = (total-true)/total\n",
        "    return score*100, true, total\n",
        "\n",
        "def calc_separability(exp):\n",
        "    wrong = 0\n",
        "    for i in range(exp.shape[0]):\n",
        "        for j in range(exp.shape[0]):\n",
        "            if i == j:\n",
        "                continue\n",
        "            eq = np.array_equal(exp[i],exp[j])\n",
        "            if eq:\n",
        "                wrong = wrong + 1\n",
        "    total = exp.shape[0]\n",
        "    score = 100*abs(wrong)/total**2\n",
        "    return wrong,total,total**2,score\n",
        "\n",
        "def calc_stability(exp, labels):\n",
        "    total = labels.shape[0]\n",
        "    label_values = np.unique(labels)\n",
        "    n_clusters = label_values.shape[0]\n",
        "    init = np.array([[np.average(exp[np.where(labels == i)], axis = 0)] for i in label_values]).squeeze()\n",
        "    ct = sklearn.cluster.KMeans(n_clusters = n_clusters, random_state=1, n_init=10, init = init)\n",
        "    ct.fit(exp)\n",
        "    error = np.sum(np.abs(labels-ct.labels_))\n",
        "    if error/total > 0.5:\n",
        "        error = total-error\n",
        "    return error, total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE6gNi2Tbnu5",
        "outputId": "202f936b-a59f-4cc8-e05a-52586ed03ec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(47.0, 53, 100)\n",
            "(0, 100, 10000, 0.0)\n",
            "(30, 100)\n"
          ]
        }
      ],
      "source": [
        "i = calc_identity(exp1,exp2)\n",
        "print(i)\n",
        "\n",
        "s = calc_separability(test_x[:100])\n",
        "print(s)\n",
        "\n",
        "def enc_exp(exp, feature_num):\n",
        "    enc_exp = np.zeros((len(exp),feature_num))\n",
        "    for i in range(len(exp)):\n",
        "        for j in range(len(exp[i])):\n",
        "            enc_exp[i][int(exp[i,j,0])] = exp[i,j,1]\n",
        "    return enc_exp\n",
        "\n",
        "enc1 = enc_exp(exp1, len(feat_list))\n",
        "sb = calc_stability(enc1, y_test[:100])\n",
        "print(sb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oXKddbdkdGL3"
      },
      "outputs": [],
      "source": [
        "from feat_atr import FeatureAttribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DwS2HlgCd6pC"
      },
      "outputs": [],
      "source": [
        "list_monotonicity = []\n",
        "list_non_sensitivity = []\n",
        "list_effective_complexity = []\n",
        "\n",
        "for i in range(len(test_x[:100])):\n",
        "    atr = np.array(sorted(exp1[i], key=lambda x: x[1], reverse=True))\n",
        "    sorted_atr = [j for i,j in atr]\n",
        "    sorted_feat = [i for i,j in atr]\n",
        "    y = np.zeros(n_classes, dtype=int)\n",
        "    np.put(y, y_test[i], 1)\n",
        "    example = FeatureAttribution(model, test_x[i], y, sorted_atr)\n",
        "    list_monotonicity.append(example.monotonicity())\n",
        "    list_non_sensitivity.append(example.non_sensitivity())\n",
        "    list_effective_complexity.append(example.effective_complexity(sorted_feat, 0.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYhK1tqceq8k",
        "outputId": "f98ce121-957f-4ad2-fae5-2a6dc70f2a64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0369442539782975\n",
            "0.93\n",
            "10.27\n",
            "0.05558073075141046\n",
            "0.0\n",
            "14.0\n"
          ]
        }
      ],
      "source": [
        "print(np.mean(list_monotonicity))\n",
        "print(np.mean(list_non_sensitivity))\n",
        "print(np.mean(list_effective_complexity))\n",
        "\n",
        "print(np.median(list_monotonicity))\n",
        "print(np.median(list_non_sensitivity))\n",
        "print(np.median(list_effective_complexity))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "60fpubM8ewvl"
      },
      "outputs": [],
      "source": [
        "def normalize_test(X_train, X_test):\n",
        "    X_test_norm = X_test.copy()\n",
        "    for i in X_train.columns:\n",
        "        scaler = sklearn.preprocessing.MinMaxScaler()\n",
        "        scaler.fit(X_train[i].values.reshape(-1,1))\n",
        "        X_test_norm[i] = scaler.transform(X_test[i].values.reshape(-1,1))\n",
        "\n",
        "    return X_test_norm\n",
        "\n",
        "def calc_similarity(exp, X_test_norm):\n",
        "    dbscan = sklearn.cluster.DBSCAN(eps=0.5, min_samples=10)\n",
        "    dbscan.fit(X_test_norm[:400])\n",
        "    labels = dbscan.labels_\n",
        "    mean_dist = []\n",
        "    for i in np.unique(labels):\n",
        "        mean_dist.append(np.mean(sklearn.metrics.pairwise_distances(exp[np.where(labels == i), :, 1].squeeze(), metric='euclidean')))\n",
        "    return np.min(mean_dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6441616736296846\n"
          ]
        }
      ],
      "source": [
        "X_test_norm = normalize_test(X_train, X_test)\n",
        "sim = calc_similarity(exp1, X_test_norm[:100])\n",
        "\n",
        "print(sim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def permute(x, x_dash):\n",
        "    x = x.copy()\n",
        "    x_dash = x_dash.copy()\n",
        "    x_rand = np.random.random(x.shape[0])\n",
        "    x_new = [x[i] if x_rand[i] > 0.5 else x_dash[i] for i in range(len(x))]\n",
        "    x_dash_new = [x_dash[i] if x_rand[i] > 0.5 else x[i] for i in range(len(x))]\n",
        "    return x_new, x_dash_new\n",
        "\n",
        "def calc_trust_score(test_x, exp, m, feat_list):\n",
        "    total_recalls = []\n",
        "    for i in range(len(test_x)):\n",
        "        feat_score = np.zeros((len(feat_list)))\n",
        "        for _ in range(m):\n",
        "            x = test_x[i].copy()\n",
        "            x_dash = test_x[np.random.randint(0,len(test_x))].copy()\n",
        "            x_perm, x_dash_perm = permute(x, x_dash)\n",
        "            for j in range(len(feat_list)):\n",
        "                z = np.concatenate((x_perm[:j+1], x_dash_perm[j+1:]))\n",
        "                z_dash = np.concatenate((x_dash_perm[:j], x_perm[j:]))\n",
        "                p_z = model.predict_proba(z.reshape(1,-1))\n",
        "                p_z_dash = model.predict_proba(z_dash.reshape(1,-1))\n",
        "                feat_score[j] = feat_score[j] + np.linalg.norm(p_z-p_z_dash)\n",
        "        feat_score = feat_score/m\n",
        "        gold_feat_fs = np.argpartition(feat_score, -6)[-6:]\n",
        "        recall = len(set(exp[i][:6, 0]).intersection(set(gold_feat_fs)))/6\n",
        "        total_recalls.append(recall)\n",
        "    return np.mean(total_recalls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.45"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "calc_trust_score(test_x[:100], exp1, 5, feat_list)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNhnP/m5Fevsl8ZztajhaGf",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
