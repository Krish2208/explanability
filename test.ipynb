{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train =  pd.read_csv('./archive/train.csv')\n",
    "df_test = pd.read_csv('./archive/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.income = df_train.income.map({'<=50K':0, '>50K':1})\n",
    "df_test.income = df_test.income.map({'<=50K':0, '>50K':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as preprocessing\n",
    "df_train.drop(['fnlwgt', 'education', 'native-country'], axis=1, inplace=True)\n",
    "df_test.drop(['fnlwgt', 'education', 'native-country'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['capital_gain_loss'] = df_train['capital-gain'] - df_train['capital-loss']\n",
    "df_test['capital_gain_loss'] = df_test['capital-gain'] - df_test['capital-loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['capital-gain', 'capital-loss'], axis=1, inplace=True)\n",
    "df_test.drop(['capital-gain', 'capital-loss'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['workclass', 'marital-status'], axis=1, inplace=True)\n",
    "df_test.drop(['workclass', 'marital-status'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df_train['occupation'] = label_encoder.fit_transform(df_train['occupation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['occupation'] = label_encoder.fit_transform(df_test['occupation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = ['relationship', 'race', 'sex']\n",
    "train = pd.get_dummies(df_train, columns=cat_col, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.get_dummies(df_test, columns=cat_col, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.income = train.income.astype('int')\n",
    "test.income = test.income.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8570726613844358\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train = train.drop(['income'], axis=1).to_numpy()\n",
    "y_train = train['income'].to_numpy()\n",
    "X_test = test.drop(['income'], axis=1).to_numpy()\n",
    "y_test = test['income'].to_numpy()\n",
    "\n",
    "clf = DecisionTreeClassifier(max_leaf_nodes=40, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime import lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train, feature_names=train.drop(['income'], axis=1).columns.to_list(), class_names=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=train.drop(['income'], axis=1).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = clf.tree_.node_count\n",
    "children_left = clf.tree_.children_left\n",
    "children_right = clf.tree_.children_right\n",
    "feature = clf.tree_.feature\n",
    "threshold = clf.tree_.threshold\n",
    "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "stack = [(0, 0)]\n",
    "while len(stack) > 0:\n",
    "    node_id, depth = stack.pop()\n",
    "    node_depth[node_id] = depth\n",
    "    is_split_node = children_left[node_id] != children_right[node_id]\n",
    "    if is_split_node:\n",
    "        stack.append((children_left[node_id], depth + 1))\n",
    "        stack.append((children_right[node_id], depth + 1))\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "    \n",
    "node_indicator = clf.decision_path(X_train)\n",
    "leaf_id = clf.apply(X_train)\n",
    "\n",
    "true_features = []\n",
    "\n",
    "sample_id = 0\n",
    "node_index = node_indicator.indices[\n",
    "    node_indicator.indptr[sample_id] : node_indicator.indptr[sample_id + 1]\n",
    "]\n",
    "for i in node_index:\n",
    "    if not is_leaves[i]:\n",
    "        true_features.append(feature_names[feature[i]])\n",
    "\n",
    "exp_fn = lambda i: explainer.explain_instance(X_train[i, :], clf.predict_proba)\n",
    "inst_expl = exp_fn(sample_id)\n",
    "explanation_features = inst_expl.as_list(label=inst_expl.available_labels()[0])\n",
    "expl_feat2 = inst_expl.as_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_feat2 = list(expl_feat2.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_feat2_l = [feature_names[i[0]] for i in expl_feat2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['capital_gain_loss',\n",
       "  'education-num',\n",
       "  'relationship_Own-child',\n",
       "  'relationship_Not-in-family',\n",
       "  'relationship_Unmarried',\n",
       "  'relationship_Other-relative',\n",
       "  'age',\n",
       "  'hours-per-week',\n",
       "  'relationship_Wife',\n",
       "  'race_Asian-Pac-Islander'],\n",
       " [('capital_gain_loss > 0.00', 0.70899522525278),\n",
       "  ('education-num > 12.00', 0.2014496135439733),\n",
       "  ('relationship_Own-child <= 0.00', 0.09969081829760053),\n",
       "  ('0.00 < relationship_Not-in-family <= 1.00', -0.09874729695227612),\n",
       "  ('relationship_Unmarried <= 0.00', 0.08525945630719363),\n",
       "  ('relationship_Other-relative <= 0.00', 0.05247914293676825),\n",
       "  ('37.00 < age <= 48.00', 0.04781548394176994),\n",
       "  ('hours-per-week <= 40.00', -0.03514981869715259),\n",
       "  ('relationship_Wife <= 0.00', -0.032593510369492026),\n",
       "  ('race_Asian-Pac-Islander <= 0.00', -0.0074040482250413275)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expl_feat2_l, explanation_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['capital_gain_loss',\n",
       "  'education-num',\n",
       "  'relationship_Not-in-family',\n",
       "  'age',\n",
       "  'education-num',\n",
       "  'hours-per-week'],\n",
       " [('capital_gain_loss > 0.00', 0.70899522525278),\n",
       "  ('education-num > 12.00', 0.2014496135439733),\n",
       "  ('relationship_Own-child <= 0.00', 0.09969081829760053),\n",
       "  ('0.00 < relationship_Not-in-family <= 1.00', -0.09874729695227612),\n",
       "  ('relationship_Unmarried <= 0.00', 0.08525945630719363),\n",
       "  ('relationship_Other-relative <= 0.00', 0.05247914293676825),\n",
       "  ('37.00 < age <= 48.00', 0.04781548394176994),\n",
       "  ('hours-per-week <= 40.00', -0.03514981869715259),\n",
       "  ('relationship_Wife <= 0.00', -0.032593510369492026),\n",
       "  ('race_Asian-Pac-Islander <= 0.00', -0.0074040482250413275)],\n",
       " 14)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_features, explanation_features, max(node_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file='x.gv',\n",
    "                                feature_names=train.drop(['income'], axis=1).columns.to_list(),\n",
    "                                class_names=['less 50K', 'great 50K'],\n",
    "                                filled=True, rounded=True,\n",
    "                                special_characters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test\n",
    "n_nodes = clf.tree_.node_count\n",
    "children_left = clf.tree_.children_left\n",
    "children_right = clf.tree_.children_right\n",
    "feature = clf.tree_.feature\n",
    "threshold = clf.tree_.threshold\n",
    "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "stack = [(0, 0)]\n",
    "while len(stack) > 0:\n",
    "    node_id, depth = stack.pop()\n",
    "    node_depth[node_id] = depth\n",
    "    is_split_node = children_left[node_id] != children_right[node_id]\n",
    "    if is_split_node:\n",
    "        stack.append((children_left[node_id], depth + 1))\n",
    "        stack.append((children_right[node_id], depth + 1))\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "    \n",
    "node_indicator = clf.decision_path(X)\n",
    "leaf_id = clf.apply(X)\n",
    "max_depth = max(node_depth)\n",
    "\n",
    "true_features = []\n",
    "\n",
    "sample_id = 0\n",
    "node_index = node_indicator.indices[\n",
    "    node_indicator.indptr[sample_id] : node_indicator.indptr[sample_id + 1]\n",
    "]\n",
    "for i in node_index:\n",
    "    if not is_leaves[i]:\n",
    "        true_features.append(feature[i])\n",
    "\n",
    "exp_fn = lambda i: explainer.explain_instance(X[i, :], clf.predict_proba)\n",
    "inst_expl = exp_fn(sample_id)\n",
    "# explanation_features = inst_expl.as_list(label=inst_expl.available_labels()[0])\n",
    "explanation_features = inst_expl.as_map()[inst_expl.available_labels()[0]]\n",
    "explanation_features = sorted(explanation_features, key=lambda x: x[1], reverse=True)\n",
    "if len(explanation_features) > max_depth:\n",
    "    recall_explanation_features = [x[0] for x in explanation_features[:max_depth]]\n",
    "elif len(explanation_features) > (2*max_depth)/3:\n",
    "    recall_explanation_features = [x[0] for x in explanation_features[:(2*max_depth)//3]]\n",
    "else:\n",
    "    recall_explanation_features = [x[0] for x in explanation_features]\n",
    "explanation_features_weights = np.array([x[1] for x in explanation_features])\n",
    "top_quartile = np.percentile(explanation_features_weights, 75)\n",
    "precision_explanation_features = [x[0] for x in explanation_features if x[1] >= top_quartile]\n",
    "\n",
    "true_features_set = set(true_features)\n",
    "precision_explanation_features_set = set(precision_explanation_features)\n",
    "recall_explanation_features_set = set(recall_explanation_features)\n",
    "\n",
    "recall = len(true_features_set.intersection(recall_explanation_features_set)) / len(true_features_set)\n",
    "precision = len(true_features_set.intersection(precision_explanation_features_set)) / len(precision_explanation_features_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0, 1, 4},\n",
       " [5, 8, 6, 10, 9, 3, 7, 0, 1],\n",
       " [5, 8, 6],\n",
       " 0.6666666666666666,\n",
       " 0.0,\n",
       " array([ 4,  1,  4,  0,  5,  7,  0,  8, -2,  0,  5,  4, -2,  8,  4,  1, -2,\n",
       "        -2,  7,  4, -2,  4,  3, -2,  6,  3, -2,  9,  1, -2, -2, 14,  4,  6,\n",
       "         4, -2,  1, -2,  4,  4, -2, -2,  0,  3, -2,  0, -2, -2,  2, -2, -2,\n",
       "        -2, -2, -2,  1,  4,  9, -2, -2, -2, -2, -2, -2,  2, -2, 14, -2, -2,\n",
       "        -2, -2, -2, -2,  2, -2, -2, -2, -2, -2, -2], dtype=int64))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_features_set, recall_explanation_features, precision_explanation_features, recall, precision, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fidelity\n",
    "fid = fidelity.Fidelity(clf, explainer, X_test, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.6666666666666666, 0.875, 0.6, 1.0, 0.6666666666666666],\n",
       " [0.0, 1.0, 0.0, 0.3333333333333333, 0.0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fid.phase_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3333333333333333, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fid.phase_two_util(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
