{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.cluster\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import random\n",
    "from skrules import SkopeRules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train =  pd.read_csv('./archive/train.csv')\n",
    "df_test = pd.read_csv('./archive/test.csv')\n",
    "\n",
    "df_train.income = df_train.income.map({'<=50K':0, '>50K':1})\n",
    "df_test.income = df_test.income.map({'<=50K':0, '>50K':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = sklearn.preprocessing.LabelEncoder()\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].dtype == 'object':\n",
    "        le.fit(df_train[col])\n",
    "        df_train[col] = le.transform(df_train[col])\n",
    "        df_test[col] = le.transform(df_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 39\n",
    "exp_iter = 10\n",
    "random.seed(random_state)\n",
    "\n",
    "#Get datasets\n",
    "X_train = df_train.drop('income', axis=1)\n",
    "y_train = df_train.income\n",
    "X_test = df_test.drop('income', axis=1)\n",
    "y_test = df_test.income\n",
    "test_x = X_test.values\n",
    "n_classes = len(np.unique(y_train))\n",
    "feat_list = [each.replace(' ','_') for each in X_train.columns]\n",
    "X = np.vstack((X_train.values, test_x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['<=50K', '>50K']\n",
    "lime_explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names = feat_list, class_names=class_names, discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_identity(exp1, exp2):\n",
    "    dis = np.array([np.array_equal(exp1[i],exp2[i]) for i in range(len(exp1))])\n",
    "    total = dis.shape[0]\n",
    "    true = np.sum(dis)\n",
    "    score = (total-true)/total\n",
    "    return score*100, true, total\n",
    "\n",
    "def calc_separability(exp):\n",
    "    wrong = 0\n",
    "    for i in range(exp.shape[0]):\n",
    "        for j in range(exp.shape[0]):\n",
    "            if i == j:\n",
    "                continue\n",
    "            eq = np.array_equal(exp[i],exp[j])\n",
    "            if eq:\n",
    "                wrong = wrong + 1\n",
    "    total = exp.shape[0]\n",
    "    score = 100*abs(wrong)/total**2\n",
    "    return wrong,total,total**2,score\n",
    "\n",
    "def calc_stability(exp, labels):\n",
    "    total = labels.shape[0]\n",
    "    label_values = np.unique(labels)\n",
    "    n_clusters = label_values.shape[0]\n",
    "    init = np.array([[np.average(exp[np.where(labels == i)], axis = 0)] for i in label_values]).squeeze()\n",
    "    ct = sklearn.cluster.KMeans(n_clusters = n_clusters, random_state=1, n_init=10, init = init)\n",
    "    ct.fit(exp)\n",
    "    error = np.sum(np.abs(labels-ct.labels_))\n",
    "    if error/total > 0.5:\n",
    "        error = total-error\n",
    "    return error, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_fn = lambda i: lime_explainer.explain_instance(test_x[i], model.predict_proba, num_features=len(feat_list))\n",
    "def exp_fn_blk(xtest, exp_fn):\n",
    "    exp1 = []\n",
    "    for i in range(len(xtest)):\n",
    "        #exp = explainer.explain_instance(dataset.test[i], c.predict_proba, num_features=5, top_labels=1)\n",
    "        exp = exp_fn(i)\n",
    "        exp1.append(exp.as_map()[exp.available_labels()[0]])\n",
    "    return np.array(exp1)\n",
    "exp_fn_wrap = lambda x: np.array(exp_fn_blk(x, exp_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = exp_fn_blk(test_x[:100], exp_fn)\n",
    "exp2 = exp_fn_blk(test_x[:100], exp_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = calc_identity(exp1,exp2)\n",
    "print(i)\n",
    "\n",
    "s = calc_separability(test_x[:100])\n",
    "print(s)\n",
    "\n",
    "def enc_exp(exp, feature_num):\n",
    "    enc_exp = np.zeros((len(exp),feature_num))\n",
    "    for i in range(len(exp)):\n",
    "        for j in range(len(exp[i])):\n",
    "            enc_exp[i][int(exp[i,j,0])] = exp[i,j,1]\n",
    "    return enc_exp\n",
    "\n",
    "enc1 = enc_exp(exp1, len(feat_list))\n",
    "sb = calc_stability(enc1, y_test[:100])\n",
    "print(sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_test(X_train, X_test):\n",
    "    X_test_norm = X_test.copy()\n",
    "    for i in X_train.columns:\n",
    "        scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "        scaler.fit(X_train[i].values.reshape(-1,1))\n",
    "        X_test_norm[i] = scaler.transform(X_test[i].values.reshape(-1,1))\n",
    "\n",
    "    return X_test_norm\n",
    "\n",
    "def calc_similarity(exp, X_test_norm):\n",
    "    dbscan = sklearn.cluster.DBSCAN(eps=0.5, min_samples=10)\n",
    "    dbscan.fit(X_test_norm[:400])\n",
    "    labels = dbscan.labels_\n",
    "    mean_dist = []\n",
    "    for i in np.unique(labels):\n",
    "        mean_dist.append(np.mean(sklearn.metrics.pairwise_distances(exp[np.where(labels == i), :, 1].squeeze(), metric='euclidean')))\n",
    "    return np.min(mean_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm = normalize_test(X_train, X_test)\n",
    "sim = calc_similarity(exp1, X_test_norm[:100])\n",
    "\n",
    "print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_trust_score(test_x, exp, m, feat_list):\n",
    "    all_feat_score = []\n",
    "    for i in range(len(exp)):\n",
    "        feat_score = np.zeros((len(feat_list)))\n",
    "        for _ in range(m):\n",
    "            x = test_x[i].copy()\n",
    "            x_dash = test_x[np.random.randint(0,len(test_x))].copy()\n",
    "            for j in range(len(feat_list)):\n",
    "                z = np.concatenate((x[:j+1], x_dash[j+1:]))\n",
    "                z_dash = np.concatenate((x_dash[:j], x[j:]))\n",
    "                p_z = model.predict_proba(z.reshape(1,-1))\n",
    "                p_z_dash = model.predict_proba(z_dash.reshape(1,-1))\n",
    "                feat_score[j] = feat_score[j] + np.linalg.norm(p_z-p_z_dash)\n",
    "        feat_score = feat_score/m\n",
    "        all_feat_score.append(feat_score)\n",
    "    return np.array(all_feat_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_trust_score(test_x[:100], exp1, 5, feat_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feat_atr import FeatureAttribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_monotonicity = []\n",
    "list_non_sensitivity = []\n",
    "list_effective_complexity = []\n",
    "\n",
    "for i in range(len(test_x[:100])):\n",
    "    atr = exp1[i]\n",
    "    sorted_atr = [j for i,j in atr]\n",
    "    sorted_feat = [i for i,j in atr]\n",
    "    y = np.zeros(n_classes, dtype=int)\n",
    "    np.put(y, y_test[i], 1)\n",
    "    example = FeatureAttribution(model, test_x[i], y, sorted_atr)\n",
    "    list_monotonicity.append(example.monotonicity())\n",
    "    list_non_sensitivity.append(example.non_sensitivity())\n",
    "    list_effective_complexity.append(example.effective_complexity(sorted_feat, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(list_monotonicity))\n",
    "print(np.mean(list_non_sensitivity))\n",
    "print(np.mean(list_effective_complexity))\n",
    "\n",
    "print(np.median(list_monotonicity))\n",
    "print(np.median(list_non_sensitivity))\n",
    "print(np.median(list_effective_complexity))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RULEFIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SkopeRules(max_depth_duplication=2,\n",
    "                    n_estimators=100,\n",
    "                    precision_min=0.3,\n",
    "                    recall_min=0.1,\n",
    "                    feature_names=feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_rules1 = clf.score_top_rules(test_x[:100])\n",
    "top_rules2 = clf.score_top_rules(test_x[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_identity_rules(top_rules1, top_rules2):\n",
    "    dis = np.array([np.array_equal(top_rules1[i],top_rules2[i]) for i in range(len(top_rules1))])\n",
    "    total = dis.shape[0]\n",
    "    true = np.sum(dis)\n",
    "    score = (total-true)/total\n",
    "    return score*100, true, total\n",
    "\n",
    "def calc_separability_rules(top_rules):\n",
    "    wrong = 0\n",
    "    for i in range(top_rules.shape[0]):\n",
    "        for j in range(top_rules.shape[0]):\n",
    "            if i == j:\n",
    "                continue\n",
    "            eq = np.array_equal(top_rules[i],top_rules[j])\n",
    "            if eq:\n",
    "                wrong = wrong + 1\n",
    "    total = top_rules.shape[0]\n",
    "    score = 100*abs(wrong)/total**2\n",
    "    return wrong,total,total**2,score\n",
    "\n",
    "def exp_enc(exp, feature_num):\n",
    "    enc_exp = np.zeros((len(exp),feature_num))\n",
    "    for i in range(len(exp)):\n",
    "        enc_exp[i][int(exp[i])] = 1\n",
    "    return enc_exp\n",
    "\n",
    "def calc_stability_rules(top_rules, labels):\n",
    "    total = labels.shape[0]\n",
    "    label_values = np.unique(labels)\n",
    "    n_clusters = label_values.shape[0]\n",
    "    init = np.array([[np.average(top_rules[np.where(labels == i)], axis = 0)] for i in label_values]).squeeze()\n",
    "    ct = sklearn.cluster.KMeans(n_clusters = n_clusters, random_state=1, n_init=10, init = init)\n",
    "    ct.fit(top_rules)\n",
    "    error = np.sum(np.abs(labels-ct.labels_))\n",
    "    if error/total > 0.5:\n",
    "        error = total-error\n",
    "    return error, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = calc_identity_rules(top_rules1, top_rules2)\n",
    "print(i)\n",
    "\n",
    "s = calc_separability_rules(top_rules1)\n",
    "print(s)\n",
    "\n",
    "enc_rules = exp_enc(top_rules1, int(max(top_rules1))+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb = calc_stability_rules(enc_rules, y_test[:100])\n",
    "print(sb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
