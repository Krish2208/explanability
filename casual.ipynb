{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdice_ml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m helpers \u001b[39m# helper functions\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 5\u001b[0m dataset \u001b[39m=\u001b[39m helpers\u001b[39m.\u001b[39;49mload_adult_income_dataset()\n\u001b[0;32m      6\u001b[0m target \u001b[39m=\u001b[39m dataset[\u001b[39m\"\u001b[39m\u001b[39mincome\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m# outcome variable\u001b[39;00m\n\u001b[0;32m      7\u001b[0m train_dataset, test_dataset, _, _ \u001b[39m=\u001b[39m train_test_split(dataset,\n\u001b[0;32m      8\u001b[0m                                                      target,\n\u001b[0;32m      9\u001b[0m                                                      test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[0;32m     10\u001b[0m                                                      random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m     11\u001b[0m                                                      stratify\u001b[39m=\u001b[39mtarget)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\interpret\\lib\\site-packages\\dice_ml\\utils\\helpers.py:25\u001b[0m, in \u001b[0;36mload_adult_income_dataset\u001b[1;34m(only_train)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_adult_income_dataset\u001b[39m(only_train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m     20\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Loads adult income dataset from https://archive.ics.uci.edu/ml/datasets/Adult and prepares\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m       the data for data analysis based on https://rpubs.com/H_Zhu/235617\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[39m    :return adult_data: returns preprocessed adult income dataset.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     raw_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mgenfromtxt(\u001b[39m'\u001b[39;49m\u001b[39mhttps://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     26\u001b[0m                              delimiter\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m, dtype\u001b[39m=\u001b[39;49m\u001b[39mstr\u001b[39;49m, invalid_raise\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     28\u001b[0m     \u001b[39m#  column names from \"https://archive.ics.uci.edu/ml/datasets/Adult\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     column_names \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mage\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mworkclass\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfnlwgt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39meducation\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39meducational-num\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmarital-status\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39moccupation\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     30\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39mrelationship\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrace\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgender\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcapital-gain\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcapital-loss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhours-per-week\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnative-country\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     31\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39mincome\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\interpret\\lib\\site-packages\\numpy\\lib\\npyio.py:1977\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001b[0m\n\u001b[0;32m   1975\u001b[0m     fname \u001b[39m=\u001b[39m os_fspath(fname)\n\u001b[0;32m   1976\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fname, \u001b[39mstr\u001b[39m):\n\u001b[1;32m-> 1977\u001b[0m     fid \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlib\u001b[39m.\u001b[39m_datasource\u001b[39m.\u001b[39mopen(fname, \u001b[39m'\u001b[39m\u001b[39mrt\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39mencoding)\n\u001b[0;32m   1978\u001b[0m     fid_ctx \u001b[39m=\u001b[39m contextlib\u001b[39m.\u001b[39mclosing(fid)\n\u001b[0;32m   1979\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\interpret\\lib\\site-packages\\numpy\\lib\\_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[39mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m ds \u001b[39m=\u001b[39m DataSource(destpath)\n\u001b[1;32m--> 193\u001b[0m \u001b[39mreturn\u001b[39;00m ds\u001b[39m.\u001b[39;49mopen(path, mode, encoding\u001b[39m=\u001b[39;49mencoding, newline\u001b[39m=\u001b[39;49mnewline)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\interpret\\lib\\site-packages\\numpy\\lib\\_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[39mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[39m=\u001b[39mmode,\n\u001b[0;32m    531\u001b[0m                               encoding\u001b[39m=\u001b[39mencoding, newline\u001b[39m=\u001b[39mnewline)\n\u001b[0;32m    532\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m not found.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data not found."
     ]
    }
   ],
   "source": [
    "import dice_ml\n",
    "from dice_ml.utils import helpers # helper functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = helpers.load_adult_income_dataset()\n",
    "target = dataset[\"income\"] # outcome variable\n",
    "train_dataset, test_dataset, _, _ = train_test_split(dataset,\n",
    "                                                     target,\n",
    "                                                     test_size=0.2,\n",
    "                                                     random_state=0,\n",
    "                                                     stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dice_ml.Data(dataframe=train_dataset,\n",
    "                 continuous_features=['age', 'hours_per_week'],\n",
    "                 outcome_name='income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = dice_ml.Model(model_path=dice_ml.utils.helpers.get_adult_income_modelpath(),backend='TF2', func=\"ohe-min-max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = dice_ml.Dice(d,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query instance (original outcome : 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass education marital_status   occupation   race  gender   \n",
       "0   29   Private   HS-grad        Married  Blue-Collar  White  Female  \\\n",
       "\n",
       "   hours_per_week  income  \n",
       "0              38       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diverse Counterfactual set (new outcome: 1.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>Private</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>Private</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age workclass    education marital_status    occupation   race  gender   \n",
       "0    29   Private      Masters        Married   Blue-Collar  White  Female  \\\n",
       "1    29   Private  Prof-school        Married   Blue-Collar  White  Female   \n",
       "2  64.0   Private        Assoc        Married   Blue-Collar  White  Female   \n",
       "3  40.0   Private      HS-grad        Married  Professional  White  Female   \n",
       "\n",
       "  hours_per_week  income  \n",
       "0             38       1  \n",
       "1             38       1  \n",
       "2             38       1  \n",
       "3             38       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate counterfactual examples\n",
    "query_instance = test_dataset.drop(columns=\"income\")[0:1]\n",
    "dice_exp = exp.generate_counterfactuals(query_instance, total_CFs=4, desired_class=\"opposite\")\n",
    "# Visualize counterfactual explanation\n",
    "dice_exp.visualize_as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.20s/it]\n"
     ]
    }
   ],
   "source": [
    "imp = exp.local_feature_importance(query_instance, total_CFs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hours_per_week': 0.6,\n",
       "  'education': 0.5,\n",
       "  'occupation': 0.3,\n",
       "  'age': 0.3,\n",
       "  'race': 0.1,\n",
       "  'workclass': 0.0,\n",
       "  'marital_status': 0.0,\n",
       "  'gender': 0.0}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.local_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn imports\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# DiCE imports\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers  # helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = helpers.load_adult_income_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Single</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>Assoc</td>\n",
       "      <td>Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Single</td>\n",
       "      <td>Service</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age      workclass     education marital_status    occupation   race   \n",
       "0   28        Private     Bachelors         Single  White-Collar  White  \\\n",
       "1   30  Self-Employed         Assoc        Married  Professional  White   \n",
       "2   32        Private  Some-college        Married  White-Collar  White   \n",
       "3   20        Private  Some-college         Single       Service  White   \n",
       "4   41  Self-Employed  Some-college        Married  White-Collar  White   \n",
       "\n",
       "   gender  hours_per_week  income  \n",
       "0  Female              60       0  \n",
       "1    Male              65       1  \n",
       "2    Male              50       0  \n",
       "3  Female              35       0  \n",
       "4    Male              50       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dataset[\"income\"]\n",
    "train_dataset, test_dataset, y_train, y_test = train_test_split(dataset,\n",
    "                                                                target,\n",
    "                                                                test_size=0.2,\n",
    "                                                                random_state=0,\n",
    "                                                                stratify=target)\n",
    "x_train = train_dataset.drop('income', axis=1)\n",
    "x_test = test_dataset.drop('income', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dice_ml.Data(dataframe=train_dataset, continuous_features=['age', 'hours_per_week'], outcome_name='income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dice_ml.data_interfaces.public_data_interface.PublicData"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = [\"age\", \"hours_per_week\"]\n",
    "categorical = x_train.columns.difference(numerical)\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "transformations = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', transformations),\n",
    "                      ('classifier', RandomForestClassifier())])\n",
    "model = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sklearn backend\n",
    "m = dice_ml.Model(model=model, backend=\"sklearn\")\n",
    "# Using method=random for generating CFs\n",
    "exp = dice_ml.Dice(d, m, method=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query instance (original outcome : 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass education marital_status   occupation   race  gender   \n",
       "0   29   Private   HS-grad        Married  Blue-Collar  White  Female  \\\n",
       "\n",
       "   hours_per_week  income  \n",
       "0              38       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diverse Counterfactual set (new outcome: 1.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>Private</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>School</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>Private</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married</td>\n",
       "      <td>Other/Unknown</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>Private</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29</td>\n",
       "      <td>Government</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age      workclass    education marital_status     occupation   race   \n",
       "0  29        Private      Masters        Married   White-Collar  White  \\\n",
       "1  29        Private        Assoc        Married   White-Collar  White   \n",
       "2  29  Self-Employed       School        Married    Blue-Collar  White   \n",
       "3  29        Private    Bachelors        Married   White-Collar  White   \n",
       "4  29        Private      Masters        Married          Sales  White   \n",
       "5  29        Private    Bachelors        Married  Other/Unknown  White   \n",
       "6  29  Self-Employed      HS-grad        Married   White-Collar  White   \n",
       "7  29        Private  Prof-school        Married    Blue-Collar  White   \n",
       "8  29     Government  Prof-school        Married    Blue-Collar  White   \n",
       "9  29  Self-Employed      HS-grad        Married   Professional  White   \n",
       "\n",
       "   gender hours_per_week  income  \n",
       "0  Female             38       1  \n",
       "1  Female             38       1  \n",
       "2  Female             38       1  \n",
       "3  Female             38       1  \n",
       "4  Female             38       1  \n",
       "5  Female             38       1  \n",
       "6  Female             38       1  \n",
       "7    Male             38       1  \n",
       "8  Female             38       1  \n",
       "9  Female             38       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e1 = exp.generate_counterfactuals(x_test[0:1], total_CFs=10, desired_class=\"opposite\")\n",
    "e1.visualize_as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CasualExplanations:\n",
    "    def __init__(self, exp, X, X_scaled, Y, categorical, numerical, classes, enc, ohe, x_min, x_max, rng, k=10, n_neighbor=10, **kwargs):\n",
    "        self.exp = exp\n",
    "        self.X = X\n",
    "        self.X_scaled = X_scaled\n",
    "        self.Y = Y\n",
    "        self.categorical = categorical\n",
    "        self.numerical = numerical\n",
    "        self.classes = classes\n",
    "        self.enc = enc\n",
    "        self.ohe = ohe\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "        self.rng = rng\n",
    "        self.k = k\n",
    "        self.n_neighbor = n_neighbor\n",
    "        if \"low_limit\" in kwargs:\n",
    "            self.low_limit = kwargs[\"low_limit\"]\n",
    "        else:\n",
    "            self.low_limit = 0\n",
    "        if \"high_limit\" in kwargs:\n",
    "            self.high_limit = kwargs[\"high_limit\"]\n",
    "        else:\n",
    "            self.high_limit = len(X)\n",
    "        self.cfs = self.generate_counterfactuals()\n",
    "        self.neigh = self.k_neighbors()\n",
    "        self.X_enc = self.enc.predict(self.X_scaled)\n",
    "        self.class_mean = {}\n",
    "        for c in classes:\n",
    "            self.class_mean[c] = self.X_enc[self.Y.argmax(\n",
    "                axis=1) == c].mean(axis=0)\n",
    "\n",
    "    def generate_counterfactuals(self):\n",
    "        return self.exp.generate_counterfactuals(self.X[self.low_limit:self.high_limit], total_CFs=self.k, desired_class=\"opposite\")\n",
    "\n",
    "    def k_neighbors(self):\n",
    "        from sklearn.neighbors import NearestNeighbors\n",
    "        neigh = NearestNeighbors(n_neighbors=self.n_neighbor)\n",
    "        neigh.fit(self.X_scaled)\n",
    "        return neigh\n",
    "\n",
    "    def average_sparsity(self, id):\n",
    "        sum_sparsity = 0\n",
    "        for i in range(self.k):\n",
    "            sum_sparsity += (\n",
    "                self.cfs.cf_examples_list[id].final_cfs_df.iloc[i, :-1] != self.X.iloc[id]).sum()\n",
    "        return sum_sparsity / self.k\n",
    "\n",
    "    def total_average_sparsity(self):\n",
    "        sum_sparsity = 0\n",
    "        for i in range(self.low_limit, self.high_limit):\n",
    "            sum_sparsity += self.average_sparsity(i)\n",
    "        return sum_sparsity / (self.high_limit - self.low_limit)\n",
    "\n",
    "    def average_proximity(self, id):\n",
    "        sum_proximity = 0\n",
    "        for i in range(self.k):\n",
    "            proximity = 0\n",
    "            for col in self.categorical:\n",
    "                if self.cfs.cf_examples_list[id].final_cfs_df.iloc[i, :-1][col] != self.X.iloc[id][col]:\n",
    "                    proximity += 1\n",
    "            for col in self.numerical:\n",
    "                proximity += abs(\n",
    "                    self.cfs.cf_examples_list[id].final_cfs_df.iloc[i, :-1][col] - self.X.iloc[id][col])\n",
    "            sum_proximity += proximity\n",
    "        return sum_proximity / self.k\n",
    "\n",
    "    def total_average_proximity(self):\n",
    "        sum_proximity = 0\n",
    "        for i in range(self.low_limit, self.high_limit):\n",
    "            sum_proximity += self.average_proximity(i)\n",
    "        return sum_proximity / (self.high_limit - self.low_limit)\n",
    "\n",
    "    def average_diversity(self, id):\n",
    "        sum_diversity = 0\n",
    "        for i in range(self.k-1):\n",
    "            diversity = 0\n",
    "            for j in range(i+1, self.k):\n",
    "                for col in self.categorical:\n",
    "                    if self.cfs.cf_examples_list[id].final_cfs_df.iloc[i, :-1][col] != self.cfs.cf_examples_list[id].final_cfs_df.iloc[j, :-1][col]:\n",
    "                        diversity += 1\n",
    "                for col in self.numerical:\n",
    "                    diversity += abs(self.cfs.cf_examples_list[id].final_cfs_df.iloc[i, :-1]\n",
    "                                     [col] - self.cfs.cf_examples_list[id].final_cfs_df.iloc[j, :-1][col])\n",
    "            sum_diversity += diversity\n",
    "        return sum_diversity / (self.k**2)\n",
    "\n",
    "    def total_average_diversity(self):\n",
    "        sum_diversity = 0\n",
    "        for i in range(self.low_limit, self.high_limit):\n",
    "            sum_diversity += self.average_diversity(i)\n",
    "        return sum_diversity / (self.high_limit - self.low_limit)\n",
    "\n",
    "    def average_interpretability(self, id):\n",
    "        x_cf = self.cfs.cf_examples_list[id].final_cfs_df.iloc[:, :-1]\n",
    "        y_cf = self.cfs.cf_examples_list[id].final_cfs_df.iloc[:, -1]\n",
    "        x_cf = np.c_[self.ohe.transform(x_cf.loc[:, self.categorical]), (x_cf.loc[:, self.numerical] - self.x_min) / (\n",
    "            self.x_max - self.x_min) * (self.rng[1] - self.rng[0]) + self.rng[0]].astype(np.float32, copy=False)\n",
    "        cf_enc = self.enc.predict(x_cf)\n",
    "        sum_interpretability = 0\n",
    "        for i in range(self.k):\n",
    "            dist_orig = np.linalg.norm(\n",
    "                cf_enc[i] - self.class_mean[self.Y[id].argmax(axis=0)])\n",
    "            dist_cf = np.linalg.norm(cf_enc[i] - self.class_mean[y_cf[i]])\n",
    "            sum_interpretability += dist_orig / (dist_cf + 1e-10)\n",
    "        return sum_interpretability / self.k\n",
    "\n",
    "    def total_average_interpretability(self):\n",
    "        sum_interpretability = 0\n",
    "        for i in range(self.low_limit, self.high_limit):\n",
    "            sum_interpretability += self.average_interpretability(i)\n",
    "        return sum_interpretability / (self.high_limit - self.low_limit)\n",
    "\n",
    "    def average_interpretability_v2(self, id):\n",
    "        sum_interpretability = 0\n",
    "        for i in range(self.k):\n",
    "            interpretability = 0\n",
    "            for col in self.categorical:\n",
    "                if self.cfs.cf_examples_list[id].final_cfs_df.iloc[i, :-1][col] != self.X.iloc[id][col]:\n",
    "                    interpretability += 1\n",
    "            for col in self.numerical:\n",
    "                interpretability += abs(self.cfs.cf_examples_list[id].final_cfs_df.iloc[i, :-1][col] - self.X.iloc[id][col])/(\n",
    "                    max(self.X.loc[:, col]) - min(self.X.loc[:, col]))\n",
    "            sum_interpretability += interpretability / \\\n",
    "                (len(self.categorical) + len(self.numerical))\n",
    "        return sum_interpretability / self.k\n",
    "\n",
    "    def total_average_interpretability_v2(self):\n",
    "        sum_interpretability = 0\n",
    "        for i in range(self.low_limit, self.high_limit):\n",
    "            sum_interpretability += self.average_interpretability_v2(i)\n",
    "        return sum_interpretability / (self.high_limit - self.low_limit)\n",
    "\n",
    "    def average_proximity_between_labels(self, id):\n",
    "        sum_proximity = 0\n",
    "        x_cf = self.cfs.cf_examples_list[id].final_cfs_df.iloc[:, :-1]\n",
    "        x_cf = np.c_[self.ohe.transform(x_cf.loc[:, self.categorical]), (x_cf.loc[:, self.numerical] - self.x_min) / (\n",
    "            self.x_max - self.x_min) * (self.rng[1] - self.rng[0]) + self.rng[0]].astype(np.float32, copy=False)\n",
    "        for i in range(self.k):\n",
    "            proximity = 0\n",
    "            k_neighbors = self.neigh.kneighbors(x_cf[i].reshape(1, -1))\n",
    "            p_sum = 0\n",
    "            for j in range(self.n_neighbor):\n",
    "                p_sum += k_neighbors[0][0][j]\n",
    "            for j in range(self.n_neighbor):\n",
    "                proximity += (k_neighbors[0][0][j]*k_neighbors[1][0][j])/p_sum\n",
    "            sum_proximity += proximity/x_cf.shape[-1]\n",
    "        return sum_proximity / self.k\n",
    "    \n",
    "    def total_average_proximity_between_labels(self):\n",
    "        sum_proximity = 0\n",
    "        for i in range(self.low_limit, self.high_limit):\n",
    "            sum_proximity += self.average_proximity_between_labels(i)\n",
    "        return sum_proximity / (self.high_limit - self.low_limit)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_num = x_train.loc[:, numerical].astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cat = x_train.loc[:, categorical].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = x_train_num.min(axis=0), x_train_num.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = (-1., 1.)\n",
    "X_num_scaled = (x_train_num - x_min) / (x_max - x_min) * (rng[1] - rng[0]) + rng[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hours_per_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20907</th>\n",
       "      <td>-0.424658</td>\n",
       "      <td>-0.122449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.204082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10939</th>\n",
       "      <td>-0.616438</td>\n",
       "      <td>-0.204082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7839</th>\n",
       "      <td>-0.342466</td>\n",
       "      <td>-0.204082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9608</th>\n",
       "      <td>-0.726027</td>\n",
       "      <td>-0.204082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25388</th>\n",
       "      <td>-0.041096</td>\n",
       "      <td>-0.612245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td>-0.397260</td>\n",
       "      <td>-0.204082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6749</th>\n",
       "      <td>-0.260274</td>\n",
       "      <td>0.102041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17884</th>\n",
       "      <td>-0.835616</td>\n",
       "      <td>-0.204082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6862</th>\n",
       "      <td>-0.260274</td>\n",
       "      <td>-0.204082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20838 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  hours_per_week\n",
       "20907 -0.424658       -0.122449\n",
       "2573   0.013699        0.204082\n",
       "10939 -0.616438       -0.204082\n",
       "7839  -0.342466       -0.204082\n",
       "9608  -0.726027       -0.204082\n",
       "...         ...             ...\n",
       "25388 -0.041096       -0.612245\n",
       "6214  -0.397260       -0.204082\n",
       "6749  -0.260274        0.102041\n",
       "17884 -0.835616       -0.204082\n",
       "6862  -0.260274       -0.204082\n",
       "\n",
       "[20838 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\interpret\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder(categories='auto', sparse=False).fit(x_train_cat)\n",
    "X_cat_ohe = ohe.transform(x_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.c_[X_cat_ohe, X_num_scaled].astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.c_[ohe.transform(x_test.loc[:, categorical]), (x_test.loc[:, numerical] - x_min) / (x_max - x_min) * (rng[1] - rng[0]) + rng[0]].astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20838, 29), (5210, 29))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae_model():\n",
    "    # encoder\n",
    "    x_in = Input(shape=(29,))\n",
    "    x = Dense(60, activation='relu')(x_in)\n",
    "    x = Dense(30, activation='relu')(x)\n",
    "    x = Dense(15, activation='relu')(x)\n",
    "    encoded = Dense(10, activation=None)(x)\n",
    "    encoder = Model(x_in, encoded)\n",
    "    \n",
    "    # decoder\n",
    "    dec_in = Input(shape=(10,))\n",
    "    x = Dense(15, activation='relu')(dec_in)\n",
    "    x = Dense(30, activation='relu')(x)\n",
    "    x = Dense(60, activation='relu')(x)\n",
    "    decoded = Dense(29, activation=None)(x)\n",
    "    decoder = Model(dec_in, decoded)\n",
    "    \n",
    "    # autoencoder = encoder + decoder\n",
    "    x_out = decoder(encoder(x_in))\n",
    "    autoencoder = Model(x_in, x_out)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return autoencoder, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 29)]              0         \n",
      "                                                                 \n",
      " model_6 (Functional)        (None, 10)                4255      \n",
      "                                                                 \n",
      " model_7 (Functional)        (None, 29)                4274      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,529\n",
      "Trainable params: 8,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "163/163 [==============================] - 2s 5ms/step - loss: 0.1030 - val_loss: 0.0651\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0520 - val_loss: 0.0413\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0341 - val_loss: 0.0285\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0247 - val_loss: 0.0217\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0196 - val_loss: 0.0182\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0168 - val_loss: 0.0162\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0151 - val_loss: 0.0145\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0138 - val_loss: 0.0133\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0089 - val_loss: 0.0088\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 20/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 21/100\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 22/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 23/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 24/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 25/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 26/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 27/100\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 28/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 29/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 30/100\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 31/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 32/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 33/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 34/100\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 35/100\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 36/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 37/100\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 38/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 39/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 40/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 41/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 42/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 43/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 44/100\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 45/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 46/100\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 47/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 48/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 49/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 50/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 51/100\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 52/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 53/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 54/100\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 55/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 56/100\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 57/100\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 58/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 59/100\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 60/100\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 61/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 62/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 63/100\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 64/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 65/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 9.9323e-04\n",
      "Epoch 66/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 9.7113e-04\n",
      "Epoch 67/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 9.8896e-04 - val_loss: 0.0010\n",
      "Epoch 68/100\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 9.7258e-04 - val_loss: 9.9896e-04\n",
      "Epoch 69/100\n",
      " 90/163 [===============>..............] - ETA: 0s - loss: 9.8614e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m ae, enc, dec \u001b[39m=\u001b[39m ae_model()\n\u001b[0;32m      2\u001b[0m ae\u001b[39m.\u001b[39msummary()\n\u001b[1;32m----> 3\u001b[0m ae\u001b[39m.\u001b[39;49mfit(X_train, X_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test, X_test), verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\interpret\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\interpret\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\interpret\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\interpret\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\interpret\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\interpret\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\interpret\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\interpret\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\interpret\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ae, enc, dec = ae_model()\n",
    "ae.summary()\n",
    "ae.fit(X_train, X_train, batch_size=128, epochs=100, validation_data=(X_test, X_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = e1.cf_examples_list[0].final_cfs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cf = cf.iloc[:, :-1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xf_cf = np.c_[ohe.transform(x_cf.loc[:, categorical]), (x_cf.loc[:, numerical] - x_min) / (x_max - x_min) * (rng[1] - rng[0]) + rng[0]].astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-4.2247496 , -1.0174646 , -2.2552083 ,  1.0896508 , -3.8075192 ,\n",
       "         3.5094485 ,  4.9353867 , -3.3043954 , -1.3877498 ,  3.4297454 ],\n",
       "       [-2.934661  ,  1.2704629 , -2.3813436 ,  1.2012497 , -3.2195582 ,\n",
       "         2.0804317 ,  5.318864  , -2.4021032 , -0.23903197,  4.0691113 ],\n",
       "       [-3.9927645 ,  0.5354843 , -1.4090974 , -1.6454202 , -4.23142   ,\n",
       "         4.1528335 ,  4.4369283 , -2.8486516 , -0.3754536 ,  2.2261927 ],\n",
       "       [-6.7905207 ,  0.29155096, -1.7372558 ,  0.28913617, -4.773374  ,\n",
       "         3.72803   ,  3.6087556 , -3.5164623 ,  0.6605272 ,  0.33095303],\n",
       "       [-6.332353  ,  0.8971953 , -1.8257024 ,  0.24094963, -4.040234  ,\n",
       "         4.449658  ,  4.5445    , -3.096514  ,  1.0572677 ,  0.9613028 ],\n",
       "       [-6.2996807 ,  0.23256153, -2.3017726 ,  0.75853693, -3.9724278 ,\n",
       "         3.7458959 ,  3.6445465 , -2.8685026 ,  0.9197155 ,  1.9694383 ],\n",
       "       [-5.5311027 , -0.3348734 , -2.7802815 ,  2.7801147 , -2.6662118 ,\n",
       "         2.136769  ,  3.41835   , -3.6901987 , -0.7368517 ,  2.4188004 ],\n",
       "       [-6.545268  ,  0.42285493, -1.5878832 ,  0.0547323 , -4.4577923 ,\n",
       "         3.0985525 ,  2.4851954 , -2.405851  ,  0.36662042,  0.2326967 ],\n",
       "       [-3.715548  ,  0.7260216 , -1.6726651 , -2.217067  , -4.010754  ,\n",
       "         4.112206  ,  2.9047966 , -2.2144783 ,  0.44550815,  1.2650459 ],\n",
       "       [-6.2678514 , -0.7140142 , -3.0689225 ,  1.8031678 , -3.2936153 ,\n",
       "         1.5574303 ,  3.1235223 , -3.4512103 , -0.26107875,  2.247464  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.predict(xf_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652/652 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "X_enc = enc.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20838,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.argmax(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class wise mean of encoded features\n",
    "class_mean = {}\n",
    "class_mean[0] = X_enc[Y_train.argmax(axis=1)==0].mean(axis=0)\n",
    "class_mean[1] = X_enc[Y_train.argmax(axis=1)==1].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "cf_enc = enc.predict(xf_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_inter = 0\n",
    "for i in cf_enc:\n",
    "    dist_orig = np.linalg.norm(i - class_mean[0])\n",
    "    dist_adv = np.linalg.norm(i - class_mean[1])\n",
    "    sum_inter += dist_orig / (dist_adv + 10e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0966775561805018"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_inter / cf_enc.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def casual_interpret_full(train: tuple, test: tuple, exp: dice_ml.explainer_interfaces.dice_random.DiceRandom, categorical : list, numerical : list, classes : list, k : int, **kwargs):\n",
    "    x_train, y_train = train\n",
    "    x_test, y_test = test\n",
    "    x_train_num = x_train.loc[:, numerical].astype(np.float32, copy=False)\n",
    "    x_train_cat = x_train.loc[:, categorical].copy()\n",
    "    x_min, x_max = x_train_num.min(axis=0), x_train_num.max(axis=0)\n",
    "    rng = (-1., 1.)\n",
    "    ohe = OneHotEncoder(categories='auto', sparse=False).fit(x_train_cat)\n",
    "    X_train = np.c_[ohe.transform(x_train_cat), (x_train_num - x_min) / (x_max - x_min) * (rng[1] - rng[0]) + rng[0]].astype(np.float32, copy=False)\n",
    "    X_test = np.c_[ohe.transform(x_test.loc[:, categorical]), (x_test.loc[:, numerical] - x_min) / (x_max - x_min) * (rng[1] - rng[0]) + rng[0]].astype(np.float32, copy=False)\n",
    "    Y_train = to_categorical(y_train)\n",
    "    Y_test = to_categorical(y_test)\n",
    "    def ae_model():\n",
    "        # encoder``\n",
    "        x_in = Input(shape=(29,))\n",
    "        x = Dense(60, activation='relu')(x_in)\n",
    "        x = Dense(30, activation='relu')(x)\n",
    "        x = Dense(15, activation='relu')(x)\n",
    "        encoded = Dense(10, activation=None)(x)\n",
    "        encoder = Model(x_in, encoded)\n",
    "        # decoder\n",
    "        dec_in = Input(shape=(10,))\n",
    "        x = Dense(15, activation='relu')(dec_in)\n",
    "        x = Dense(30, activation='relu')(x)\n",
    "        x = Dense(60, activation='relu')(x)\n",
    "        decoded = Dense(29, activation=None)(x)\n",
    "        decoder = Model(dec_in, decoded)\n",
    "        # autoencoder = encoder + decoder\n",
    "        x_out = decoder(encoder(x_in))\n",
    "        autoencoder = Model(x_in, x_out)\n",
    "        autoencoder.compile(optimizer='adam', loss='mse')\n",
    "        return autoencoder, encoder, decoder\n",
    "    ae, enc, dec = ae_model()\n",
    "    ae.fit(X_train, X_train, batch_size=128, epochs=10, validation_data=(X_test, X_test), verbose=1)\n",
    "    train_ce = CasualExplanations(exp, x_train, X_train, Y_train, categorical, numerical, classes, enc, ohe, x_min, x_max, rng, k, **kwargs)\n",
    "    test_ce = CasualExplanations(exp, x_test, X_test, Y_test, categorical, numerical, classes, enc, ohe, x_min, x_max, rng, k, **kwargs)\n",
    "    return train_ce, test_ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\interpret\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "163/163 [==============================] - 2s 5ms/step - loss: 0.0988 - val_loss: 0.0616\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0370\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.0268\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.0219\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0202 - val_loss: 0.0191\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0161 - val_loss: 0.0156\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0148 - val_loss: 0.0145\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0137 - val_loss: 0.0134\n",
      "Epoch 10/10\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0128 - val_loss: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78/652 [==>...........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652/652 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77/163 [=============>................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "train, test = casual_interpret_full((x_train, y_train), (x_test, y_test), exp, categorical, numerical, [0,1], k=10, low_limit=0, high_limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.16, 2.12)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.total_average_sparsity(), test.total_average_sparsity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.72, 8.02)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.total_average_proximity(), test.total_average_proximity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13.540000000000001, 6.3260000000000005)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.total_average_diversity(), test.total_average_diversity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0051886650549895, 1.1345499695099577)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.total_average_interpretability(), test.total_average_interpretability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2142189684092815, 0.23437517472742525)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.total_average_interpretability_v2(), test.total_average_interpretability_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356.2896740772791, 83.67289459096745)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.total_average_proximity_between_labels(), test.total_average_proximity_between_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
