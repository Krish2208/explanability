{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Datasets/SPECT Heart/spect_train_binary.csv')\n",
    "test = pd.read_csv('../Datasets/SPECT Heart/spect_test_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('OVERALL_DIAGNOSIS', axis=1)\n",
    "y_train = train['OVERALL_DIAGNOSIS']\n",
    "X_test = test.drop('OVERALL_DIAGNOSIS', axis=1)\n",
    "y_test = test['OVERALL_DIAGNOSIS']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = autosklearn.classification.AutoSklearnClassifier()\n",
    "automl.fit(X_train, y_train)\n",
    "y_hat = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8128342245989305"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./models/spect_heart_automl.pkl', 'wb') as f:\n",
    "    pickle.dump(automl, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "model = sklearn.ensemble.RandomForestClassifier(n_estimators=100, n_jobs=5, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7647058823529411"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krish/anaconda3/envs/interpret/lib/python3.7/site-packages/sklearn/model_selection/_search.py:925: UserWarning: One or more of the test scores are non-finite: [0.7375    nan 0.625  0.7375 0.7375    nan 0.7    0.6875 0.7375    nan\n",
      " 0.6625 0.6625 0.7375    nan 0.6625 0.6625 0.7375    nan 0.6625 0.6625\n",
      " 0.7375    nan 0.625  0.7375 0.7375    nan 0.7    0.6875 0.7375    nan\n",
      " 0.6625 0.6625 0.7375    nan 0.6625 0.6625 0.7375    nan 0.6625 0.6625\n",
      " 0.7375    nan 0.625  0.7375 0.7375    nan 0.7    0.6875 0.7375    nan\n",
      " 0.6625 0.6625 0.7375    nan 0.6625 0.6625 0.7375    nan 0.6625 0.6625\n",
      " 0.7375    nan 0.625  0.7375 0.7375    nan 0.7    0.6875 0.7375    nan\n",
      " 0.6625 0.6625 0.7375    nan 0.6625 0.6625 0.7375    nan 0.6625 0.6625\n",
      " 0.7375    nan 0.625  0.7375 0.7375    nan 0.7    0.6875 0.7375    nan\n",
      " 0.6625 0.6625 0.7375    nan 0.6625 0.6625 0.7375    nan 0.6625 0.6625\n",
      " 0.7375    nan 0.625  0.7375 0.7375    nan 0.7    0.6875 0.7375    nan\n",
      " 0.6625 0.6625 0.7375    nan 0.6625 0.6625 0.7375    nan 0.6625 0.6625\n",
      " 0.7375    nan 0.625  0.7375 0.7375    nan 0.7    0.6875 0.7375    nan\n",
      " 0.6625 0.6625 0.7375    nan 0.6625 0.6625 0.7375    nan 0.6625 0.6625\n",
      " 0.7375    nan 0.625  0.7375 0.7375    nan 0.7    0.6875 0.7375    nan\n",
      " 0.6625 0.6625 0.7375    nan 0.6625 0.6625 0.7375    nan 0.6625 0.6625\n",
      " 0.7375    nan 0.625  0.7375 0.7375    nan 0.7    0.6875 0.7375    nan\n",
      " 0.6625 0.6625 0.7375    nan 0.6625 0.6625 0.7375    nan 0.6625 0.6625\n",
      " 0.7375    nan 0.625  0.7375 0.7375    nan 0.7    0.6875 0.7375    nan\n",
      " 0.6625 0.6625 0.7375    nan 0.6625 0.6625 0.7375    nan 0.6625 0.6625\n",
      " 0.6875    nan 0.725  0.5375 0.6875    nan 0.75   0.7375 0.6875    nan\n",
      " 0.65   0.6625 0.6875    nan 0.6625 0.6625 0.6875    nan 0.6625 0.6625\n",
      " 0.6875    nan 0.725  0.5375 0.6875    nan 0.75   0.7375 0.6875    nan\n",
      " 0.65   0.6625 0.6875    nan 0.6625 0.6625 0.6875    nan 0.6625 0.6625\n",
      " 0.6875    nan 0.725  0.5375 0.6875    nan 0.75   0.7375 0.6875    nan\n",
      " 0.65   0.6625 0.6875    nan 0.6625 0.6625 0.6875    nan 0.6625 0.6625\n",
      " 0.6875    nan 0.725  0.5375 0.6875    nan 0.75   0.7375 0.6875    nan\n",
      " 0.65   0.6625 0.6875    nan 0.6625 0.6625 0.6875    nan 0.6625 0.6625\n",
      " 0.6875    nan 0.725  0.5375 0.6875    nan 0.75   0.7375 0.6875    nan\n",
      " 0.65   0.6625 0.6875    nan 0.6625 0.6625 0.6875    nan 0.6625 0.6625\n",
      " 0.6875    nan 0.725  0.5375 0.6875    nan 0.75   0.7375 0.6875    nan\n",
      " 0.65   0.6625 0.6875    nan 0.6625 0.6625 0.6875    nan 0.6625 0.6625\n",
      " 0.6875    nan 0.725  0.5375 0.6875    nan 0.75   0.7375 0.6875    nan\n",
      " 0.65   0.6625 0.6875    nan 0.6625 0.6625 0.6875    nan 0.6625 0.6625\n",
      " 0.6875    nan 0.725  0.5375 0.6875    nan 0.75   0.7375 0.6875    nan\n",
      " 0.65   0.6625 0.6875    nan 0.6625 0.6625 0.6875    nan 0.6625 0.6625\n",
      " 0.6875    nan 0.725  0.5375 0.6875    nan 0.75   0.7375 0.6875    nan\n",
      " 0.65   0.6625 0.6875    nan 0.6625 0.6625 0.6875    nan 0.6625 0.6625\n",
      " 0.6875    nan 0.725  0.5375 0.6875    nan 0.75   0.7375 0.6875    nan\n",
      " 0.65   0.6625 0.6875    nan 0.6625 0.6625 0.6875    nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.4875 0.65      nan 0.7    0.725  0.65      nan\n",
      " 0.75   0.7375 0.65      nan 0.6625 0.6625 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.4875 0.65      nan 0.7    0.725  0.65      nan\n",
      " 0.75   0.7375 0.65      nan 0.6625 0.6625 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.4875 0.65      nan 0.7    0.725  0.65      nan\n",
      " 0.75   0.7375 0.65      nan 0.6625 0.6625 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.4875 0.65      nan 0.7    0.725  0.65      nan\n",
      " 0.75   0.7375 0.65      nan 0.6625 0.6625 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.4875 0.65      nan 0.7    0.725  0.65      nan\n",
      " 0.75   0.7375 0.65      nan 0.6625 0.6625 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.4875 0.65      nan 0.7    0.725  0.65      nan\n",
      " 0.75   0.7375 0.65      nan 0.6625 0.6625 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.4875 0.65      nan 0.7    0.725  0.65      nan\n",
      " 0.75   0.7375 0.65      nan 0.6625 0.6625 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.4875 0.65      nan 0.7    0.725  0.65      nan\n",
      " 0.75   0.7375 0.65      nan 0.6625 0.6625 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.4875 0.65      nan 0.7    0.725  0.65      nan\n",
      " 0.75   0.7375 0.65      nan 0.6625 0.6625 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.4875 0.65      nan 0.7    0.725  0.65      nan\n",
      " 0.75   0.7375 0.65      nan 0.6625 0.6625 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.5    0.65      nan 0.6875 0.65   0.65      nan\n",
      " 0.6625 0.6875 0.65      nan 0.7625 0.7375 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.5    0.65      nan 0.6875 0.65   0.65      nan\n",
      " 0.6625 0.6875 0.65      nan 0.7625 0.7375 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.5    0.65      nan 0.6875 0.65   0.65      nan\n",
      " 0.6625 0.6875 0.65      nan 0.7625 0.7375 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.5    0.65      nan 0.6875 0.65   0.65      nan\n",
      " 0.6625 0.6875 0.65      nan 0.7625 0.7375 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.5    0.65      nan 0.6875 0.65   0.65      nan\n",
      " 0.6625 0.6875 0.65      nan 0.7625 0.7375 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.5    0.65      nan 0.6875 0.65   0.65      nan\n",
      " 0.6625 0.6875 0.65      nan 0.7625 0.7375 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.5    0.65      nan 0.6875 0.65   0.65      nan\n",
      " 0.6625 0.6875 0.65      nan 0.7625 0.7375 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.5    0.65      nan 0.6875 0.65   0.65      nan\n",
      " 0.6625 0.6875 0.65      nan 0.7625 0.7375 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.5    0.65      nan 0.6875 0.65   0.65      nan\n",
      " 0.6625 0.6875 0.65      nan 0.7625 0.7375 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.5    0.65      nan 0.6875 0.65   0.65      nan\n",
      " 0.6625 0.6875 0.65      nan 0.7625 0.7375 0.65      nan 0.6625 0.6625\n",
      " 0.65      nan 0.775  0.475  0.65      nan 0.6875 0.625  0.65      nan\n",
      " 0.6625 0.6375 0.65      nan 0.675  0.6875 0.65      nan 0.7625 0.7375\n",
      " 0.65      nan 0.775  0.475  0.65      nan 0.6875 0.625  0.65      nan\n",
      " 0.6625 0.6375 0.65      nan 0.675  0.6875 0.65      nan 0.7625 0.7375\n",
      " 0.65      nan 0.775  0.475  0.65      nan 0.6875 0.625  0.65      nan\n",
      " 0.6625 0.6375 0.65      nan 0.675  0.6875 0.65      nan 0.7625 0.7375\n",
      " 0.65      nan 0.775  0.475  0.65      nan 0.6875 0.625  0.65      nan\n",
      " 0.6625 0.6375 0.65      nan 0.675  0.6875 0.65      nan 0.7625 0.7375\n",
      " 0.65      nan 0.775  0.475  0.65      nan 0.6875 0.625  0.65      nan\n",
      " 0.6625 0.6375 0.65      nan 0.675  0.6875 0.65      nan 0.7625 0.7375\n",
      " 0.65      nan 0.775  0.475  0.65      nan 0.6875 0.625  0.65      nan\n",
      " 0.6625 0.6375 0.65      nan 0.675  0.6875 0.65      nan 0.7625 0.7375\n",
      " 0.65      nan 0.775  0.475  0.65      nan 0.6875 0.625  0.65      nan\n",
      " 0.6625 0.6375 0.65      nan 0.675  0.6875 0.65      nan 0.7625 0.7375\n",
      " 0.65      nan 0.775  0.475  0.65      nan 0.6875 0.625  0.65      nan\n",
      " 0.6625 0.6375 0.65      nan 0.675  0.6875 0.65      nan 0.7625 0.7375\n",
      " 0.65      nan 0.775  0.475  0.65      nan 0.6875 0.625  0.65      nan\n",
      " 0.6625 0.6375 0.65      nan 0.675  0.6875 0.65      nan 0.7625 0.7375\n",
      " 0.65      nan 0.775  0.475  0.65      nan 0.6875 0.625  0.65      nan\n",
      " 0.6625 0.6375 0.65      nan 0.675  0.6875 0.65      nan 0.7625 0.7375]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(random_state=42), n_jobs=5,\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'degree': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['linear', 'ploy', 'rbf', 'sigmoid']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.svm\n",
    "import sklearn.model_selection\n",
    "\n",
    "model = sklearn.svm.SVC(random_state=42)\n",
    "params = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['linear', 'ploy', 'rbf', 'sigmoid'], 'degree': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "gridSearch = sklearn.model_selection.GridSearchCV(model, param_grid=params, cv=5, n_jobs=5, verbose=3)\n",
    "gridSearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8449197860962567"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = gridSearch.predict(X_test)\n",
    "sklearn.metrics.accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./models/spect_heart_gridsearch.pkl', 'wb') as f:\n",
    "    pickle.dump(gridSearch, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:56:09] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:56:09] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:56:09] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:56:09] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:56:09] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "xgb = xgboost.cv({'n_estimators': 1000, 'max_depth': 6, 'eta': 0.1, 'silent': 1, 'objective': 'binary:logistic', 'eval_metric': 'error'}, xgboost.DMatrix(X_train, y_train), num_boost_round=100, early_stopping_rounds=10, nfold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.026146</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.115920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.184375</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.030619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.032775</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.178125</td>\n",
       "      <td>0.028980</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.168750</td>\n",
       "      <td>0.030298</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.101550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.033366</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.101550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.035630</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.101550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.168750</td>\n",
       "      <td>0.030298</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.082916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.035630</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.101550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.159375</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.091856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-error-mean  train-error-std  test-error-mean  test-error-std\n",
       "0          0.187500         0.026146           0.4000        0.115920\n",
       "1          0.184375         0.026882           0.3375        0.030619\n",
       "2          0.187500         0.032775           0.3375        0.050000\n",
       "3          0.178125         0.028980           0.3000        0.100000\n",
       "4          0.168750         0.030298           0.2875        0.101550\n",
       "5          0.175000         0.033366           0.2750        0.101550\n",
       "6          0.171875         0.035630           0.2750        0.101550\n",
       "7          0.168750         0.030298           0.2625        0.082916\n",
       "8          0.171875         0.035630           0.2750        0.101550\n",
       "9          0.159375         0.025000           0.2375        0.091856"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgboost.XGBClassifier(n_estimators=1000, max_depth=6, eta=0.1, silent=1, objective='binary:logistic', eval_metric='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:57:16] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.679144385026738"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "sklearn.metrics.accuracy_score(y_test, y_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
