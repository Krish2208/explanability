{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../Datasets/Hepatitis/hepatitis_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop('protime', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                0.000000\n",
       "sex                0.000000\n",
       "steroid            0.006452\n",
       "antivirals         0.000000\n",
       "fatigue            0.006452\n",
       "malaise            0.006452\n",
       "anorexia           0.006452\n",
       "liver_big          0.064516\n",
       "liver_firm         0.070968\n",
       "spleen_palpable    0.032258\n",
       "spiders            0.032258\n",
       "ascites            0.032258\n",
       "varices            0.032258\n",
       "bilirubin          0.038710\n",
       "alk_phosphate      0.187097\n",
       "sgot               0.025806\n",
       "albumin            0.103226\n",
       "histology          0.000000\n",
       "class              0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()/len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krish/anaconda3/envs/interpret2/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "continuous_features = ['age', 'bilirubin', 'alk_phosphate', 'sgot', 'albumin']\n",
    "for column in continuous_features:\n",
    "    dataset[column] = dataset[column].fillna(dataset[column].mean())\n",
    "for column in dataset.columns.drop(continuous_features):\n",
    "    dataset[column] = dataset[column].fillna(dataset[column].mode().sample(1, random_state=1).values[0])\n",
    "for column in dataset.select_dtypes('bool'):\n",
    "    dataset[column] = dataset[column].astype(np.int)\n",
    "dataset['sex'] = dataset['sex'].replace({'female': 0,'male': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['class'] = dataset['class'].replace({'live': 0,'die': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dataset.drop('class', axis=1), dataset['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = autosklearn.classification.AutoSklearnClassifier()\n",
    "automl.fit(X_train, y_train)\n",
    "y_hat = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7692307692307693"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./models/hepatitis_automl.pkl', 'wb') as f:\n",
    "    pickle.dump(automl, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/hepatitis_automl.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1330/3483595073.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./models/hepatitis_automl.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mautoml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/hepatitis_automl.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('./models/hepatitis_automl.pkl', 'rb') as f:\n",
    "    automl = pickle.load(f)\n",
    "\n",
    "len(automl.show_models())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "model = sklearn.ensemble.RandomForestClassifier(n_estimators=512, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8717948717948718"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./models/hepatitis_rf2.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "import pickle\n",
    "with open('./models/hepatitis_rf2.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8717948717948718"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "sklearn.metrics.accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = ['age', 'bilirubin', 'alk_phosphate', 'sgot', 'albumin']\n",
    "categorical_features = X_train.columns.drop(continuous_features).tolist()\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X_train.columns.tolist(), class_names=['No', 'Yes'], categorical_features=categorical_features, discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_fn = lambda i: explainer.explain_instance(X_test.iloc[i], model.predict_proba, num_features=len(X_test.columns))\n",
    "def exp_fn_blk(xtest, exp_fn):\n",
    "    exp1 = []\n",
    "    for i in tqdm.tqdm(range(len(xtest))):\n",
    "        exp = exp_fn(i)\n",
    "        exp1.append(exp.as_map()[exp.available_labels()[0]])\n",
    "    return np.array(exp1)\n",
    "exp_fn_wrap = lambda x: np.array(exp_fn_blk(x, exp_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = exp_fn_wrap(test_x)\n",
    "exp2 = exp_fn_wrap(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./hepatitis_lime1.npy', exp1)\n",
    "np.save('./hepatitis_lime2.npy', exp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krish/anaconda3/envs/interpret2/lib/python3.7/site-packages/lime/submodular_pick.py:58: UserWarning: Requested sample size larger than\n",
      "                              size of input data. Using all data\n",
      "  size of input data. Using all data\"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 133.02945971488953 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krish/anaconda3/envs/interpret2/lib/python3.7/site-packages/lime/submodular_pick.py:58: UserWarning: Requested sample size larger than\n",
      "                              size of input data. Using all data\n",
      "  size of input data. Using all data\"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 158.08447742462158 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from lime import submodular_pick\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "exp1 = submodular_pick.SubmodularPick(explainer, X_test.values, model.predict_proba, sample_size=500, num_features=len(X_test.columns), num_exps_desired=5)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "exp2 = submodular_pick.SubmodularPick(explainer, X_test.values, model.predict_proba, sample_size=500, num_features=len(X_test.columns), num_exps_desired=5)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_imp(sp_obj):\n",
    "    W_pick=pd.DataFrame([dict(this.as_list(this.available_labels()[0])) for this in sp_obj.sp_explanations]).fillna(0)\n",
    "    W_pick['prediction'] = [this.available_labels()[0] for this in sp_obj.sp_explanations]\n",
    "    W=pd.DataFrame([dict(this.as_list(this.available_labels()[0])) for this in sp_obj.explanations]).fillna(0)\n",
    "    W['prediction'] = [this.available_labels()[0] for this in sp_obj.explanations]\n",
    "    np.abs(W.drop(\"prediction\", axis=1)).mean(axis=0).sort_values(ascending=False).head(25).sort_values(ascending=True)\n",
    "    grped_coeff = W.groupby(\"prediction\").mean()\n",
    "    grped_coeff = grped_coeff.T\n",
    "    return grped_coeff[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp1 = get_feature_imp(exp1)\n",
    "feat_imp2 = get_feature_imp(exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.18744669,  0.08023318,  0.09831124,  0.01976555,  0.03615287,\n",
       "        0.0331906 , -0.02994793,  0.00493468, -0.02086241,  0.01185868,\n",
       "        0.01147735, -0.00334327,  0.00638221, -0.0063429 ,  0.00145957,\n",
       "       -0.00027922, -0.0022545 ,  0.        , -0.01809966, -0.02058307,\n",
       "       -0.03281419, -0.02034057,  0.01025667, -0.01015185, -0.00488674,\n",
       "       -0.00157352, -0.00114962, -0.00223699,  0.02531155, -0.01491504,\n",
       "        0.0022497 , -0.02231687, -0.00936111,  0.01108054, -0.0095815 ,\n",
       "        0.00523939,  0.00042867,  0.00086861,  0.00369731,  0.00962114,\n",
       "        0.01251484,  0.00195863,  0.00095824,  0.00034751, -0.00839321])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_identity(feat_imp1, feat_imp2):\n",
    "    sum = 0\n",
    "    for i in range(len(feat_imp1)):\n",
    "        if(feat_imp1[i] == feat_imp2[i]):\n",
    "            sum += 1\n",
    "    return sum/len(feat_imp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022222222222222223"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = global_identity(feat_imp1, feat_imp2)\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_fi(feat_imp):\n",
    "    return np.abs(feat_imp) / np.sum(np.abs(feat_imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_feat_imp = normal_fi(feat_imp1 + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entropy Ratio\n",
    "Ser = np.sum(normal_feat_imp*np.log(normal_feat_imp))/np.log(1/len(normal_feat_imp))\n",
    "\n",
    "# Kullback-Leibler Divergence\n",
    "Skl = np.sum(normal_feat_imp*np.log(normal_feat_imp/(1/len(normal_feat_imp))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gini(pfi):\n",
    "    sum = 0\n",
    "    for i in range(len(pfi)):\n",
    "        sum_curr = 0\n",
    "        for j in range(len(pfi)):\n",
    "            sum_curr += np.abs(pfi[i]-pfi[j])\n",
    "        sum += sum_curr\n",
    "    \n",
    "    return sum/(2*len(pfi)**2)*(np.sum(pfi)/len(pfi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sg = calc_gini(normal_feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7797565416242837, 0.83839251161613, 0.00032078091530043587)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ser, Skl, Sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_alpha_fi(normal_pfi, alpha):\n",
    "    j_inst = 0\n",
    "    sum = 0\n",
    "    for i in range(len(normal_pfi)-1, -1, -1):\n",
    "        sum += normal_pfi[i]\n",
    "        if sum<=alpha:\n",
    "            j_inst = i\n",
    "        else:\n",
    "            break\n",
    "    return 1- (j_inst/len(normal_pfi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_alpha_fi(normal_feat_imp, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp =explainer.explain_instance(X_test.iloc[0], model.predict_proba, num_features=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_imp_all(sp_obj):\n",
    "    W_pick=pd.DataFrame([dict(this.as_list(this.available_labels()[0])) for this in sp_obj.sp_explanations]).fillna(0)\n",
    "    W_pick['prediction'] = [this.available_labels()[0] for this in sp_obj.sp_explanations]\n",
    "    W=pd.DataFrame([dict(this.as_list(this.available_labels()[0])) for this in sp_obj.explanations]).fillna(0)\n",
    "    W['prediction'] = [this.available_labels()[0] for this in sp_obj.explanations]\n",
    "    np.abs(W.drop(\"prediction\", axis=1)).mean(axis=0).sort_values(ascending=False).head(25).sort_values(ascending=True)\n",
    "    grped_coeff = W.groupby(\"prediction\").mean()\n",
    "    grped_coeff = grped_coeff.T\n",
    "    return grped_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_feat_imp, class2_feat_imp = get_feature_imp_all(exp1)[0].values, get_feature_imp_all(exp1)[1].values\n",
    "normal_class1_fi, normal_class2_fi = normal_fi(class1_feat_imp), normal_fi(class2_feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2672899583401707"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(normal_class1_fi - normal_class2_fi, ord=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ciu import determine_ciu\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_fn_blk(xtest):\n",
    "    exp1 = []\n",
    "    for i in tqdm.tqdm(range(len(xtest))):\n",
    "        exp = determine_ciu(X_test.iloc[i:i+1], model.predict_proba, X_train.to_dict('list'), samples = 1000, prediction_index = 1)\n",
    "        exp_list = [[feat_list.index(i), exp.ci[i]] for i in exp.ci]\n",
    "        exp1.append(exp_list)\n",
    "    return np.array(exp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [01:18<00:00,  2.02s/it]\n",
      "100%|██████████| 39/39 [00:54<00:00,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "exp1 = exp_fn_blk(X_test)\n",
    "exp2 = exp_fn_blk(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./explanations/hepatitis_ciu1.npy', exp1)\n",
    "np.save('./explanations/hepatitis_ciu2.npy', exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_exp(exp, feature_num):\n",
    "    enc_exp = np.zeros((len(exp),feature_num))\n",
    "    for i in range(len(exp)):\n",
    "        for j in range(len(exp[i])):\n",
    "            enc_exp[i][int(exp[i,j,0])] = exp[i,j,1]\n",
    "    return enc_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krish/anaconda3/envs/interpret/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py:984: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  self._check_params(X)\n"
     ]
    }
   ],
   "source": [
    "i = metrics.calc_identity(exp1, exp2)\n",
    "s = metrics.calc_separability(exp1)\n",
    "enc1 = enc_exp(exp1, len(feat_list))\n",
    "sb = metrics.calc_stability(enc1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17.94871794871795, 32, 39), (0, 39, 1521, 0.0), (14, 39))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i, s, sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm = metrics.normalize_test(X_train, X_test)\n",
    "sim = metrics.calc_similarity(exp1, X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6829878898876597"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [01:17<00:00,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "list_monotonicity = []\n",
    "list_non_sensitivity = []\n",
    "list_effective_complexity = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(X_test))):\n",
    "    atr = exp1[i]\n",
    "    sorted_atr = [j for i,j in atr]\n",
    "    sorted_feat = [i for i,j in atr]\n",
    "    y = np.zeros(2, dtype=int)\n",
    "    np.put(y, y_test.iloc[i], 1)\n",
    "    example = metrics.FeatureAttribution(model, X_test.to_numpy()[i], y, sorted_atr)\n",
    "    list_monotonicity.append(example.monotonicity())\n",
    "    list_non_sensitivity.append(example.non_sensitivity())\n",
    "    list_effective_complexity.append(example.effective_complexity(sorted_feat, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20520679866470337\n",
      "0.48717948717948717\n",
      "8.23076923076923\n",
      "0.21164522230736263\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(list_monotonicity))\n",
    "print(np.mean(list_non_sensitivity))\n",
    "print(np.mean(list_effective_complexity))\n",
    "\n",
    "print(np.median(list_monotonicity))\n",
    "print(np.median(list_non_sensitivity))\n",
    "print(np.median(list_effective_complexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [03:28<00:00,  5.36s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3034188034188034"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.calc_trust_score(model, X_test.to_numpy(), exp1, 3, X_train.columns.to_list())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RULEFIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrules import SkopeRules\n",
    "import metrics_rules\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SkopeRules(max_depth_duplication=2,\n",
    "                    n_estimators=512,\n",
    "                    precision_min=0.3,\n",
    "                    recall_min=0.1,\n",
    "                    feature_names=X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 11.780784368515015 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.07526111602783203 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "top_rules1 = clf.score_top_rules(X_test)\n",
    "top_rules2 = clf.score_top_rules(X_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 39, 39)\n",
      "(332, 39, 1521, 21.82774490466798)\n",
      "(17, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krish/anaconda3/envs/interpret/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py:984: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  self._check_params(X)\n"
     ]
    }
   ],
   "source": [
    "i = metrics_rules.calc_identity_rules(top_rules1, top_rules2)\n",
    "print(i)\n",
    "\n",
    "s = metrics_rules.calc_separability_rules(top_rules1)\n",
    "print(s)\n",
    "\n",
    "enc_rules = metrics_rules.exp_enc(clf, top_rules1)\n",
    "sb = metrics_rules.calc_stability_rules(enc_rules, y_test)\n",
    "print(sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9688432163003059\n"
     ]
    }
   ],
   "source": [
    "X_test_norm = metrics_rules.normalize_test(X_train, X_test)\n",
    "sim = metrics_rules.calc_similarity(exp1, X_test_norm)\n",
    "print(sim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RULEMATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = ['age', 'bilirubin', 'alk_phosphate', 'sgot', 'albumin']\n",
    "categorical_features = X_train.columns.drop(continuous_features).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rulematrix\n",
    "import time\n",
    "import metrics_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_continuous = [True if i in continuous_features else False for i in X_train.columns.tolist()]\n",
    "is_categorical = [True if i in categorical_features else False for i in X_train.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = rulematrix.surrogate.rule_surrogate(\n",
    "    model.predict,\n",
    "    X_train,\n",
    "    sampling_rate=4,\n",
    "    is_continuous=is_continuous,\n",
    "    is_categorical=is_categorical,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_fn_blk(xtest):\n",
    "    exp1 = []\n",
    "    for i in range(len(xtest)):\n",
    "        queried_rules = np.arange(surrogate.student.n_rules)[surrogate.student.decision_path(test_x[i].reshape(1,-1)).reshape(-1)]\n",
    "        exp1.append(queried_rules[-1])\n",
    "    return np.array(exp1)\n",
    "exp_fn_wrap = lambda x: np.array(exp_fn_blk(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.01602959632873535 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "exp1 = exp_fn_blk(test_x)\n",
    "exp2 = exp_fn_blk(test_x)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_exp(exp, n_features):\n",
    "    enc = []\n",
    "    for i in range(exp.shape[0]):\n",
    "        new = np.zeros(n_features)\n",
    "        for j in surrogate.student.rule_list[exp[i]].clauses:\n",
    "            new[j.feature_idx] = 1\n",
    "        enc.append(new)\n",
    "    return np.array(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_exp = enc_exp(exp1, X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 39, 39)\n",
      "(440, 39, 1521, 28.928336620644313)\n",
      "(15, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krish/anaconda3/envs/interpret/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py:984: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  self._check_params(X)\n"
     ]
    }
   ],
   "source": [
    "i = metrics_rules.calc_identity_rules(exp1, exp2)\n",
    "print(i)\n",
    "\n",
    "s = metrics_rules.calc_separability_rules(exp1)\n",
    "print(s)\n",
    "\n",
    "sb = metrics_rules.calc_stability_rules(enc_exp, y_test)\n",
    "print(sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm = metrics_rules.normalize_test(X_train, X_test)\n",
    "sim = metrics_rules.calc_similarity(enc_exp, X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1212315681063432"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RuleMatrix Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 18)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rule(clauses=[Clause(feature_idx=1, category=1)], output=array([0.97727273, 0.02272727])),\n",
       " Rule(clauses=[Clause(feature_idx=16, category=0), Clause(feature_idx=4, category=1)], output=array([0.02173913, 0.97826087])),\n",
       " Rule(clauses=[Clause(feature_idx=13, category=2)], output=array([0.04347826, 0.95652174])),\n",
       " Rule(clauses=[Clause(feature_idx=10, category=0), Clause(feature_idx=11, category=0)], output=array([0.99196787, 0.00803213])),\n",
       " Rule(clauses=[Clause(feature_idx=6, category=1)], output=array([0.76, 0.24])),\n",
       " Rule(clauses=[Clause(feature_idx=13, category=1)], output=array([0.1, 0.9])),\n",
       " Rule(clauses=[Clause(feature_idx=8, category=1)], output=array([0.93617021, 0.06382979])),\n",
       " Rule(clauses=[], output=array([0.38888889, 0.61111111]))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surrogate.student.rule_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANCHOR Global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anchor import anchor_tabular\n",
    "import anchor_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "    y_train.unique().tolist(),\n",
    "    X_train.columns.tolist(),\n",
    "    X_train.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance using Anchor\n",
    "def calc_fi(X_test, model, explainer):\n",
    "    all_exps = []\n",
    "    for i in range(len(X_test)):\n",
    "        exp = explainer.explain_instance(X_test.values[i], model.predict, threshold=0.95)\n",
    "        all_exps.append(exp.exp_map)\n",
    "    fi = anchor_utils.greedy_pick_anchor(all_exps, X_test.values, k = len(X_test.columns))\n",
    "    return fi\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4358974358974359\n",
      "1 0.5897435897435898\n",
      "2 0.6666666666666666\n",
      "3 0.6923076923076923\n",
      "4 0.717948717948718\n",
      "5 0.7435897435897436\n",
      "6 0.7692307692307693\n",
      "7 0.7948717948717948\n",
      "8 0.8205128205128205\n",
      "9 0.8461538461538461\n",
      "10 0.8717948717948718\n",
      "11 0.8974358974358975\n",
      "12 0.9230769230769231\n",
      "13 0.9487179487179487\n",
      "14 0.9743589743589743\n",
      "15 1.0\n",
      "16 1.0\n",
      "17 1.0\n",
      "0 0.4358974358974359\n",
      "1 0.5897435897435898\n",
      "2 0.6153846153846154\n",
      "3 0.6410256410256411\n",
      "4 0.6666666666666666\n",
      "5 0.6923076923076923\n",
      "6 0.717948717948718\n",
      "7 0.7435897435897436\n",
      "8 0.7692307692307693\n",
      "9 0.7948717948717948\n",
      "10 0.8205128205128205\n",
      "11 0.8461538461538461\n",
      "12 0.8717948717948718\n",
      "13 0.8974358974358975\n",
      "14 0.9230769230769231\n",
      "15 0.9487179487179487\n",
      "16 0.9743589743589743\n",
      "17 1.0\n"
     ]
    }
   ],
   "source": [
    "exp1 = calc_fi(X_test, model, explainer)\n",
    "exp2 = calc_fi(X_test, model, explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_fi(feat_imp):\n",
    "    feat_imp = np.array(feat_imp) + 1e-9\n",
    "    return np.abs(feat_imp) / np.sum(np.abs(feat_imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_feat_imp1 = normal_fi(exp1)\n",
    "normal_feat_imp2 = normal_fi(exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def global_identity(feat_imp1, feat_imp2):\n",
    "    sum = 0\n",
    "    for i in range(len(feat_imp1)):\n",
    "        if(feat_imp1[i] == feat_imp2[i]):\n",
    "            sum += 1\n",
    "    return sum/len(feat_imp1)\n",
    "\n",
    "i = global_identity(normal_feat_imp1, normal_feat_imp2)\n",
    "i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entropy Ratio\n",
    "Ser = np.sum(normal_feat_imp1*np.log(normal_feat_imp1))/np.log(1/len(normal_feat_imp1))\n",
    "\n",
    "# Kullback-Leibler Divergence\n",
    "Skl = np.sum(normal_feat_imp1*np.log(normal_feat_imp1/(1/len(normal_feat_imp1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gini(pfi):\n",
    "    sum = 0\n",
    "    for i in range(len(pfi)):\n",
    "        sum_curr = 0\n",
    "        for j in range(len(pfi)):\n",
    "            sum_curr += np.abs(pfi[i]-pfi[j])\n",
    "        sum += sum_curr\n",
    "    \n",
    "    return sum/(2*len(pfi)**2)*(np.sum(pfi)/len(pfi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sg = calc_gini(normal_feat_imp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8728877639924251, 0.3674016170393269, 0.001338302340968637)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ser, Skl, Sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_alpha_fi(normal_pfi, alpha):\n",
    "    j_inst = 0\n",
    "    sum = 0\n",
    "    for i in range(len(normal_pfi)-1, -1, -1):\n",
    "        sum += normal_pfi[i]\n",
    "        if sum<=alpha:\n",
    "            j_inst = i\n",
    "        else:\n",
    "            break\n",
    "    return 1- (j_inst/len(normal_pfi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6111111111111112"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_alpha_fi(normal_feat_imp1, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation Feature Importance\n",
    "def calc_pfi(model, X_test, y_test, feat):\n",
    "    pfi = []\n",
    "    for i in range(len(feat)):\n",
    "        X_test_copy = X_test.copy()\n",
    "        X_test_copy[feat] = np.random.permutation(X_test_copy[feat])\n",
    "        y_hat = model.predict(X_test_copy)\n",
    "        loss_perm = sklearn.metrics.accuracy_score(y_test, y_hat)\n",
    "        loss_orig = sklearn.metrics.accuracy_score(y_test, model.predict(X_test))\n",
    "        pfi.append(loss_perm-loss_orig)\n",
    "    \n",
    "    sum_pfi = np.sum(np.abs(pfi))\n",
    "    normal_pfi = np.abs(pfi)/sum_pfi\n",
    "    return np.array(normal_pfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_pfi = calc_pfi(model, X_test, y_test, X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entropy Ratio\n",
    "Ser = np.sum(normal_pfi*np.log(normal_pfi))/np.log(1/len(normal_pfi))\n",
    "\n",
    "# Kullback-Leibler Divergence\n",
    "Skl = np.sum(normal_pfi*np.log(normal_pfi/(1/len(normal_pfi))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gini(pfi):\n",
    "    sum = 0\n",
    "    for i in range(len(pfi)):\n",
    "        sum_curr = 0\n",
    "        for j in range(len(pfi)):\n",
    "            sum_curr += np.abs(pfi[i]-pfi[j])\n",
    "        sum += sum_curr\n",
    "    \n",
    "    return sum/(2*len(pfi)**2)*(np.sum(pfi)/len(pfi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sg = calc_gini(normal_pfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9860372710737533, 0.040357477351582974, 0.0004198003878719077)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ser, Skl, Sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Groups Contrasts (PCG)\n",
    "\n",
    "groups = []\n",
    "# Get 4 quartiles based on output\n",
    "quartiles = np.quantile(model.predict_proba(X_test)[:,1], [0.25, 0.5, 0.75])\n",
    "\n",
    "# Group 1: 0-0.25\n",
    "# Group 2: 0.25-0.5\n",
    "# Group 3: 0.5-0.75\n",
    "# Group 4: 0.75-1\n",
    "\n",
    "groups.append(np.where(model.predict_proba(X_test)[:,1] <= quartiles[0])[0])\n",
    "groups.append(np.where((model.predict_proba(X_test)[:,1] > quartiles[0]) & (model.predict_proba(X_test)[:,1] <= quartiles[1]))[0])\n",
    "groups.append(np.where((model.predict_proba(X_test)[:,1] > quartiles[1]) & (model.predict_proba(X_test)[:,1] <= quartiles[2]))[0])\n",
    "groups.append(np.where(model.predict_proba(X_test)[:,1] > quartiles[2])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_group0 = y_test.iloc[groups[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_group0 = X_test.iloc[groups[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pgc(model, X_test, normal_pfi):\n",
    "    groups = []\n",
    "    quartiles = np.quantile(model.predict_proba(X_test)[:,1], [0.25, 0.5, 0.75])\n",
    "    groups.append(np.where(model.predict_proba(X_test)[:,1] <= quartiles[0])[0])\n",
    "    groups.append(np.where((model.predict_proba(X_test)[:,1] > quartiles[0]) & (model.predict_proba(X_test)[:,1] <= quartiles[1]))[0])\n",
    "    groups.append(np.where((model.predict_proba(X_test)[:,1] > quartiles[1]) & (model.predict_proba(X_test)[:,1] <= quartiles[2]))[0])\n",
    "    groups.append(np.where(model.predict_proba(X_test)[:,1] > quartiles[2])[0])\n",
    "    \n",
    "    group_pfi = []\n",
    "    for i in range(len(groups)):\n",
    "        group_pfi.append(calc_pfi(model, X_test.iloc[groups[i]], y_test.iloc[groups[i]], X_test.columns.tolist()))\n",
    "    \n",
    "    c_score = 0\n",
    "    for i in range(len(groups)):\n",
    "        print(i)\n",
    "        for k in range(X_test.columns.shape[0]):\n",
    "            print(k)\n",
    "            ik = np.argsort(normal_pfi, axis=0)[-k:]\n",
    "            ikg = np.argsort(group_pfi[i], axis=0)[-k:]\n",
    "            # print(ik, ikg)\n",
    "            position_overlap = 0\n",
    "            for j in range(k):\n",
    "                if ik[j] == ikg[j]:\n",
    "                    position_overlap += 1\n",
    "            c_score += position_overlap\n",
    "    \n",
    "    return c_score/(len(groups)*X_test.columns.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_alpha_fi(normal_pfi, alpha):\n",
    "    j_inst = 0\n",
    "    sum = 0\n",
    "    for i in range(len(normal_pfi)-1, -1, -1):\n",
    "        sum += normal_pfi[i]\n",
    "        if sum<=alpha:\n",
    "            j_inst = i\n",
    "        else:\n",
    "            break\n",
    "    return 1- (j_inst/len(normal_pfi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7222222222222222"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_alpha_fi(normal_pfi, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anchor import utils\n",
    "from anchor import anchor_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "    y_train.unique().tolist(),\n",
    "    X_train.columns.tolist(),\n",
    "    X_train.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance using Anchor\n",
    "all_exps = []\n",
    "for i in range(len(X_test)):\n",
    "    exp = explainer.explain_instance(X_test.values[i], model.predict, threshold=0.95)\n",
    "    all_exps.append(exp.exp_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = explainer.explain_instance(X_test.values[0], model.predict, threshold=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': [7, 11, 13],\n",
       " 'mean': [0.21712671158443816, 0.8010204081632653, 1.0],\n",
       " 'precision': [0.21712671158443816, 0.8010204081632653, 1.0],\n",
       " 'coverage': [1.0, 0.121, 0.0578],\n",
       " 'examples': [{'covered': array([[ 72.        ,   0.        ,   1.        ,   1.        ,\n",
       "             1.        ,   0.        ,   0.        ,   1.        ,\n",
       "             1.        ,   0.        ,   0.        ,   0.        ,\n",
       "             0.        ,   1.        , 115.        ,  52.        ,\n",
       "             3.4       ,   1.        ],\n",
       "          [ 45.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   0.        ,   0.        ,   1.        ,\n",
       "             1.        ,   1.        ,   0.        ,   0.        ,\n",
       "             0.        ,   1.2       ,  81.        ,  65.        ,\n",
       "             3.        ,   0.        ],\n",
       "          [ 32.        ,   0.        ,   1.        ,   1.        ,\n",
       "             1.        ,   0.        ,   0.        ,   1.        ,\n",
       "             1.        ,   0.        ,   1.        ,   0.        ,\n",
       "             0.        ,   1.        ,  59.        , 249.        ,\n",
       "             3.7       ,   0.        ],\n",
       "          [ 52.        ,   0.        ,   0.        ,   1.        ,\n",
       "             0.        ,   0.        ,   0.        ,   1.        ,\n",
       "             0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             0.        ,   0.7       ,  75.        ,  55.        ,\n",
       "             4.        ,   0.        ],\n",
       "          [ 35.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   0.        ,   0.        ,   1.        ,\n",
       "             0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             0.        ,   0.9       ,  58.        ,  92.        ,\n",
       "             4.3       ,   0.        ],\n",
       "          [ 64.        ,   0.        ,   1.        ,   1.        ,\n",
       "             1.        ,   1.        ,   0.        ,   0.        ,\n",
       "             1.        ,   0.        ,   0.        ,   0.        ,\n",
       "             0.        ,   1.        ,  80.        ,  38.        ,\n",
       "             4.3       ,   0.        ],\n",
       "          [ 47.        ,   0.        ,   0.        ,   1.        ,\n",
       "             0.        ,   0.        ,   0.        ,   1.        ,\n",
       "             0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             0.        ,   1.42751678, 105.32539683,  60.        ,\n",
       "             3.81726619,   0.        ],\n",
       "          [ 35.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   0.        ,   0.        ,   1.        ,\n",
       "             0.        ,   1.        ,   1.        ,   1.        ,\n",
       "             0.        ,   1.5       , 138.        ,  58.        ,\n",
       "             2.6       ,   1.        ],\n",
       "          [ 62.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             0.        ,   1.        , 105.32539683,  60.        ,\n",
       "             3.81726619,   0.        ],\n",
       "          [ 44.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   0.        ,   0.        ,   1.        ,\n",
       "             1.        ,   0.        ,   0.        ,   0.        ,\n",
       "             0.        ,   0.9       , 126.        , 142.        ,\n",
       "             4.3       ,   1.        ]]),\n",
       "   'covered_true': array([[ 31.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   1.        ,   1.        ,\n",
       "             0.        ,   1.        ,   0.        ,   0.        ,\n",
       "             0.        ,   8.        , 105.32539683, 101.        ,\n",
       "             2.2       ,   1.        ],\n",
       "          [ 47.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             1.        ,   0.        ,   1.        ,   1.        ,\n",
       "             1.        ,   1.        , 166.        ,  30.        ,\n",
       "             2.6       ,   1.        ],\n",
       "          [ 35.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   0.        ,   0.        ,   1.        ,\n",
       "             0.        ,   1.        ,   1.        ,   1.        ,\n",
       "             0.        ,   1.5       , 138.        ,  58.        ,\n",
       "             2.6       ,   1.        ],\n",
       "          [ 31.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   1.        ,   1.        ,\n",
       "             0.        ,   1.        ,   0.        ,   0.        ,\n",
       "             0.        ,   8.        , 105.32539683, 101.        ,\n",
       "             2.2       ,   1.        ],\n",
       "          [ 31.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   1.        ,   1.        ,\n",
       "             0.        ,   1.        ,   0.        ,   0.        ,\n",
       "             0.        ,   8.        , 105.32539683, 101.        ,\n",
       "             2.2       ,   1.        ],\n",
       "          [ 46.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   1.        ,   1.        ,   1.        ,\n",
       "             0.        ,   0.        ,   1.        ,   1.        ,\n",
       "             1.        ,   7.6       , 105.32539683, 242.        ,\n",
       "             3.3       ,   1.        ],\n",
       "          [ 47.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             1.        ,   0.        ,   1.        ,   1.        ,\n",
       "             1.        ,   1.        , 166.        ,  30.        ,\n",
       "             2.6       ,   1.        ],\n",
       "          [ 47.        ,   0.        ,   1.        ,   0.        ,\n",
       "             0.        ,   0.        ,   0.        ,   1.        ,\n",
       "             0.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   2.        ,  84.        ,  23.        ,\n",
       "             4.2       ,   1.        ],\n",
       "          [ 41.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   0.        ,   0.        ,   1.        ,\n",
       "             1.        ,   1.        ,   1.        ,   0.        ,\n",
       "             1.        ,   4.2       ,  65.        , 120.        ,\n",
       "             3.4       ,   1.        ],\n",
       "          [ 57.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             0.        ,   0.        ,   1.        ,   1.        ,\n",
       "             0.        ,   4.6       ,  82.        ,  55.        ,\n",
       "             3.3       ,   1.        ]]),\n",
       "   'covered_false': array([[ 24.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   0.        ,   0.        ,   1.        ,\n",
       "             0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             0.        ,   1.        , 105.32539683,  34.        ,\n",
       "             4.1       ,   1.        ],\n",
       "          [ 38.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   1.        ,   0.        ,\n",
       "             1.        ,   0.        ,   0.        ,   0.        ,\n",
       "             0.        ,   0.6       ,  76.        ,  18.        ,\n",
       "             4.4       ,   1.        ],\n",
       "          [ 45.        ,   1.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             0.        ,   1.        ,   0.        ,   0.        ,\n",
       "             0.        ,   1.        ,  85.        ,  75.        ,\n",
       "             3.81726619,   0.        ],\n",
       "          [ 32.        ,   0.        ,   0.        ,   1.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             0.        ,   1.        ,  55.        ,  45.        ,\n",
       "             4.1       ,   0.        ],\n",
       "          [ 54.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   0.        ,   0.        ,   0.        ,\n",
       "             0.        ,   3.2       ,  85.        ,  28.        ,\n",
       "             3.8       ,   1.        ],\n",
       "          [ 64.        ,   0.        ,   1.        ,   1.        ,\n",
       "             1.        ,   1.        ,   0.        ,   0.        ,\n",
       "             1.        ,   0.        ,   0.        ,   0.        ,\n",
       "             0.        ,   1.        ,  80.        ,  38.        ,\n",
       "             4.3       ,   0.        ],\n",
       "          [ 28.        ,   0.        ,   1.        ,   0.        ,\n",
       "             0.        ,   0.        ,   0.        ,   1.        ,\n",
       "             0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             0.        ,   0.7       ,  85.        ,  31.        ,\n",
       "             4.9       ,   0.        ],\n",
       "          [ 45.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   0.        ,   0.        ,   1.        ,\n",
       "             1.        ,   1.        ,   0.        ,   0.        ,\n",
       "             0.        ,   1.2       ,  81.        ,  65.        ,\n",
       "             3.        ,   0.        ],\n",
       "          [ 42.        ,   0.        ,   1.        ,   0.        ,\n",
       "             0.        ,   0.        ,   0.        ,   1.        ,\n",
       "             0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             0.        ,   0.9       ,  60.        ,  63.        ,\n",
       "             4.7       ,   0.        ],\n",
       "          [ 36.        ,   0.        ,   1.        ,   0.        ,\n",
       "             0.        ,   0.        ,   0.        ,   1.        ,\n",
       "             0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             0.        ,   0.6       , 120.        ,  30.        ,\n",
       "             4.        ,   1.        ]]),\n",
       "   'uncovered_true': array([], dtype=float64),\n",
       "   'uncovered_false': array([], dtype=float64)},\n",
       "  {'covered': array([[ 33. ,   0. ,   0. ,   0. ,   1. ,   1. ,   0. ,   1. ,   0. ,\n",
       "             0. ,   0. ,   1. ,   0. ,   0.7,  63. ,  80. ,   3. ,   1. ],\n",
       "          [ 33. ,   0. ,   0. ,   0. ,   1. ,   1. ,   0. ,   1. ,   0. ,\n",
       "             0. ,   0. ,   1. ,   0. ,   0.7,  63. ,  80. ,   3. ,   1. ],\n",
       "          [ 20. ,   0. ,   0. ,   0. ,   1. ,   1. ,   1. ,   1. ,   0. ,\n",
       "             0. ,   1. ,   1. ,   0. ,   1. , 160. , 118. ,   2.9,   1. ],\n",
       "          [ 65. ,   0. ,   1. ,   0. ,   1. ,   1. ,   0. ,   1. ,   1. ,\n",
       "             1. ,   1. ,   1. ,   0. ,   0.3, 180. ,  53. ,   2.9,   1. ],\n",
       "          [ 50. ,   0. ,   1. ,   0. ,   1. ,   0. ,   0. ,   1. ,   1. ,\n",
       "             1. ,   0. ,   1. ,   1. ,   2.8, 155. ,  75. ,   2.4,   1. ],\n",
       "          [ 54. ,   0. ,   0. ,   0. ,   1. ,   1. ,   0. ,   1. ,   0. ,\n",
       "             1. ,   0. ,   1. ,   0. ,   3.9, 120. ,  28. ,   3.5,   1. ],\n",
       "          [ 47. ,   0. ,   1. ,   0. ,   1. ,   1. ,   0. ,   1. ,   1. ,\n",
       "             0. ,   0. ,   1. ,   1. ,   1.7,  86. ,  20. ,   2.1,   1. ],\n",
       "          [ 54. ,   0. ,   0. ,   0. ,   1. ,   1. ,   0. ,   1. ,   0. ,\n",
       "             0. ,   0. ,   1. ,   0. ,   1.2,  85. ,  92. ,   3.1,   1. ],\n",
       "          [ 35. ,   0. ,   0. ,   0. ,   1. ,   0. ,   0. ,   1. ,   0. ,\n",
       "             1. ,   1. ,   1. ,   0. ,   1.5, 138. ,  58. ,   2.6,   1. ],\n",
       "          [ 47. ,   0. ,   1. ,   0. ,   1. ,   1. ,   0. ,   1. ,   1. ,\n",
       "             0. ,   1. ,   1. ,   1. ,   1. , 166. ,  30. ,   2.6,   1. ]]),\n",
       "   'covered_true': array([[ 38.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   1.        ,   1.        ,\n",
       "             1.        ,   0.        ,   1.        ,   1.        ,\n",
       "             1.        ,   1.2       , 118.        ,  16.        ,\n",
       "             2.8       ,   1.        ],\n",
       "          [ 47.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             1.        ,   0.        ,   1.        ,   1.        ,\n",
       "             1.        ,   1.        , 166.        ,  30.        ,\n",
       "             2.6       ,   1.        ],\n",
       "          [ 57.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   1.        ,   1.        ,   1.        ,\n",
       "             0.        ,   0.        ,   1.        ,   1.        ,\n",
       "             0.        ,   4.1       , 105.32539683,  48.        ,\n",
       "             2.6       ,   0.        ],\n",
       "          [ 57.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   1.        ,   1.        ,   1.        ,\n",
       "             0.        ,   0.        ,   1.        ,   1.        ,\n",
       "             0.        ,   4.1       , 105.32539683,  48.        ,\n",
       "             2.6       ,   0.        ],\n",
       "          [ 35.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   0.        ,   0.        ,   1.        ,\n",
       "             0.        ,   1.        ,   1.        ,   1.        ,\n",
       "             0.        ,   1.5       , 138.        ,  58.        ,\n",
       "             2.6       ,   1.        ],\n",
       "          [ 54.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             0.        ,   1.        ,   0.        ,   1.        ,\n",
       "             0.        ,   3.9       , 120.        ,  28.        ,\n",
       "             3.5       ,   1.        ],\n",
       "          [ 35.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   0.        ,   0.        ,   1.        ,\n",
       "             0.        ,   1.        ,   1.        ,   1.        ,\n",
       "             0.        ,   1.5       , 138.        ,  58.        ,\n",
       "             2.6       ,   1.        ],\n",
       "          [ 54.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             0.        ,   1.        ,   0.        ,   1.        ,\n",
       "             0.        ,   3.9       , 120.        ,  28.        ,\n",
       "             3.5       ,   1.        ],\n",
       "          [ 46.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   1.        ,   1.        ,   1.        ,\n",
       "             0.        ,   0.        ,   1.        ,   1.        ,\n",
       "             1.        ,   7.6       , 105.32539683, 242.        ,\n",
       "             3.3       ,   1.        ],\n",
       "          [ 57.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   1.        ,   1.        ,   1.        ,\n",
       "             0.        ,   0.        ,   1.        ,   1.        ,\n",
       "             0.        ,   4.1       , 105.32539683,  48.        ,\n",
       "             2.6       ,   0.        ]]),\n",
       "   'covered_false': array([[ 20. ,   0. ,   0. ,   0. ,   1. ,   1. ,   1. ,   1. ,   0. ,\n",
       "             0. ,   1. ,   1. ,   0. ,   1. , 160. , 118. ,   2.9,   1. ],\n",
       "          [ 20. ,   0. ,   0. ,   0. ,   1. ,   1. ,   1. ,   1. ,   0. ,\n",
       "             0. ,   1. ,   1. ,   0. ,   1. , 160. , 118. ,   2.9,   1. ],\n",
       "          [ 54. ,   0. ,   0. ,   0. ,   1. ,   1. ,   0. ,   1. ,   0. ,\n",
       "             0. ,   0. ,   1. ,   0. ,   1.2,  85. ,  92. ,   3.1,   1. ],\n",
       "          [ 20. ,   0. ,   0. ,   0. ,   1. ,   1. ,   1. ,   1. ,   0. ,\n",
       "             0. ,   1. ,   1. ,   0. ,   1. , 160. , 118. ,   2.9,   1. ],\n",
       "          [ 65. ,   0. ,   1. ,   0. ,   1. ,   1. ,   0. ,   1. ,   1. ,\n",
       "             1. ,   1. ,   1. ,   0. ,   0.3, 180. ,  53. ,   2.9,   1. ],\n",
       "          [ 65. ,   0. ,   1. ,   0. ,   1. ,   1. ,   0. ,   1. ,   1. ,\n",
       "             1. ,   1. ,   1. ,   0. ,   0.3, 180. ,  53. ,   2.9,   1. ],\n",
       "          [ 20. ,   0. ,   0. ,   0. ,   1. ,   1. ,   1. ,   1. ,   0. ,\n",
       "             0. ,   1. ,   1. ,   0. ,   1. , 160. , 118. ,   2.9,   1. ],\n",
       "          [ 20. ,   0. ,   0. ,   0. ,   1. ,   1. ,   1. ,   1. ,   0. ,\n",
       "             0. ,   1. ,   1. ,   0. ,   1. , 160. , 118. ,   2.9,   1. ],\n",
       "          [ 20. ,   0. ,   0. ,   0. ,   1. ,   1. ,   1. ,   1. ,   0. ,\n",
       "             0. ,   1. ,   1. ,   0. ,   1. , 160. , 118. ,   2.9,   1. ],\n",
       "          [ 65. ,   0. ,   1. ,   0. ,   1. ,   1. ,   0. ,   1. ,   1. ,\n",
       "             1. ,   1. ,   1. ,   0. ,   0.3, 180. ,  53. ,   2.9,   1. ]]),\n",
       "   'uncovered_true': array([], dtype=float64),\n",
       "   'uncovered_false': array([], dtype=float64)},\n",
       "  {'covered': array([[ 47.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             1.        ,   0.        ,   0.        ,   1.        ,\n",
       "             1.        ,   1.7       ,  86.        ,  20.        ,\n",
       "             2.1       ,   1.        ],\n",
       "          [ 46.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   1.        ,   1.        ,   1.        ,\n",
       "             0.        ,   0.        ,   1.        ,   1.        ,\n",
       "             1.        ,   7.6       , 105.32539683, 242.        ,\n",
       "             3.3       ,   1.        ],\n",
       "          [ 57.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             0.        ,   0.        ,   1.        ,   1.        ,\n",
       "             0.        ,   4.6       ,  82.        ,  55.        ,\n",
       "             3.3       ,   1.        ],\n",
       "          [ 54.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             0.        ,   1.        ,   0.        ,   1.        ,\n",
       "             0.        ,   3.9       , 120.        ,  28.        ,\n",
       "             3.5       ,   1.        ],\n",
       "          [ 48.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             1.        ,   0.        ,   1.        ,   1.        ,\n",
       "             1.        ,   4.8       , 123.        , 157.        ,\n",
       "             2.7       ,   1.        ],\n",
       "          [ 48.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             1.        ,   0.        ,   1.        ,   1.        ,\n",
       "             1.        ,   4.8       , 123.        , 157.        ,\n",
       "             2.7       ,   1.        ],\n",
       "          [ 47.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             1.        ,   0.        ,   0.        ,   1.        ,\n",
       "             1.        ,   1.7       ,  86.        ,  20.        ,\n",
       "             2.1       ,   1.        ],\n",
       "          [ 57.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             0.        ,   0.        ,   1.        ,   1.        ,\n",
       "             0.        ,   4.6       ,  82.        ,  55.        ,\n",
       "             3.3       ,   1.        ],\n",
       "          [ 57.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   1.        ,   1.        ,   1.        ,\n",
       "             0.        ,   0.        ,   1.        ,   1.        ,\n",
       "             0.        ,   4.1       , 105.32539683,  48.        ,\n",
       "             2.6       ,   0.        ],\n",
       "          [ 57.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             0.        ,   0.        ,   1.        ,   1.        ,\n",
       "             0.        ,   4.6       ,  82.        ,  55.        ,\n",
       "             3.3       ,   1.        ]]),\n",
       "   'covered_true': array([[ 48.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             1.        ,   0.        ,   1.        ,   1.        ,\n",
       "             1.        ,   4.8       , 123.        , 157.        ,\n",
       "             2.7       ,   1.        ],\n",
       "          [ 57.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   1.        ,   1.        ,   1.        ,\n",
       "             0.        ,   0.        ,   1.        ,   1.        ,\n",
       "             0.        ,   4.1       , 105.32539683,  48.        ,\n",
       "             2.6       ,   0.        ],\n",
       "          [ 46.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   1.        ,   1.        ,   1.        ,\n",
       "             0.        ,   0.        ,   1.        ,   1.        ,\n",
       "             1.        ,   7.6       , 105.32539683, 242.        ,\n",
       "             3.3       ,   1.        ],\n",
       "          [ 57.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             0.        ,   0.        ,   1.        ,   1.        ,\n",
       "             0.        ,   4.6       ,  82.        ,  55.        ,\n",
       "             3.3       ,   1.        ],\n",
       "          [ 48.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             1.        ,   0.        ,   1.        ,   1.        ,\n",
       "             1.        ,   4.8       , 123.        , 157.        ,\n",
       "             2.7       ,   1.        ],\n",
       "          [ 47.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             1.        ,   0.        ,   0.        ,   1.        ,\n",
       "             1.        ,   1.7       ,  86.        ,  20.        ,\n",
       "             2.1       ,   1.        ],\n",
       "          [ 54.        ,   0.        ,   0.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             0.        ,   1.        ,   0.        ,   1.        ,\n",
       "             0.        ,   3.9       , 120.        ,  28.        ,\n",
       "             3.5       ,   1.        ],\n",
       "          [ 47.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             1.        ,   0.        ,   0.        ,   1.        ,\n",
       "             1.        ,   1.7       ,  86.        ,  20.        ,\n",
       "             2.1       ,   1.        ],\n",
       "          [ 50.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   0.        ,   0.        ,   1.        ,\n",
       "             1.        ,   1.        ,   0.        ,   1.        ,\n",
       "             1.        ,   2.8       , 155.        ,  75.        ,\n",
       "             2.4       ,   1.        ],\n",
       "          [ 57.        ,   0.        ,   1.        ,   0.        ,\n",
       "             1.        ,   1.        ,   1.        ,   1.        ,\n",
       "             0.        ,   0.        ,   1.        ,   1.        ,\n",
       "             0.        ,   4.1       , 105.32539683,  48.        ,\n",
       "             2.6       ,   0.        ]]),\n",
       "   'covered_false': array([], shape=(0, 18), dtype=float64),\n",
       "   'uncovered_true': array([], dtype=float64),\n",
       "   'uncovered_false': array([], dtype=float64)}],\n",
       " 'all_precision': 0,\n",
       " 'num_preds': 1000001,\n",
       " 'names': ['liver_big <= 1.00', 'ascites > 0.00', 'bilirubin > 1.50'],\n",
       " 'instance': array([ 30. ,   0. ,   1. ,   0. ,   1. ,   1. ,   1. ,   1. ,   1. ,\n",
       "          0. ,   1. ,   1. ,   1. ,   2.5, 165. ,  64. ,   2.8,   1. ]),\n",
       " 'prediction': 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.exp_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats = len(X_train.columns)\n",
    "imp = np.zeros(num_feats).astype(int)\n",
    "for i in range(len(X_test)):\n",
    "    exp = explainer.explain_instance(X_test.values[i], model.predict, threshold=0.95).features()\n",
    "    for j in exp:\n",
    "        imp[j] = imp[j] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anchor_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4358974358974359\n",
      "1 0.5897435897435898\n",
      "2 0.6666666666666666\n",
      "3 0.6923076923076923\n",
      "4 0.717948717948718\n",
      "5 0.7435897435897436\n",
      "6 0.7692307692307693\n",
      "7 0.7948717948717948\n",
      "8 0.8205128205128205\n",
      "9 0.8461538461538461\n",
      "10 0.8717948717948718\n",
      "11 0.8974358974358975\n",
      "12 0.9230769230769231\n",
      "13 0.9487179487179487\n",
      "14 0.9743589743589743\n",
      "15 1.0\n",
      "16 1.0\n",
      "17 1.0\n"
     ]
    }
   ],
   "source": [
    "p = anchor_utils.greedy_pick_anchor(all_exps, X_test.values, k = len(X_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 1, 20, 0, 3, 5, 6, 7, 13, 14, 15, 16, 19, 26, 29, 32, 0, 0]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exps2 = []\n",
    "for i in range(len(X_test)):\n",
    "    exp = explainer.explain_instance(X_test.values[i], model.predict, threshold=0.95)\n",
    "    all_exps2.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  3,  1,  0,  8,  2,  0,  0,  1,  2, 17,  5,  2, 13,  4,  2, 21,\n",
       "       11])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anchor import anchor_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc_exp = anchor_tabular.AnchorTabularExplainer(class_names=y_train.unique().tolist(), feature_names=X_train.columns.values.tolist(), train_data=X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<anchor.anchor_explanation.AnchorExplanation at 0x7f19903b9eb8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anc_exp.explain_instance(X_test.iloc[0].values, model.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_utils.greedy_pick_anchor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
