{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_table('../Datasets/Diabetic Retinopathy/messidor_features.arff', sep=',', index_col=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dataset.iloc[:, :-1], dataset.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = autosklearn.classification.AutoSklearnClassifier()\n",
    "automl.fit(X_train, y_train)\n",
    "y_hat = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7569444444444444"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./models/diabetic_retinopathy_automl.pkl', 'wb') as f:\n",
    "    pickle.dump(automl, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/diabetic_retinopathy_automl.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2135/3836314717.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./models/diabetic_retinopathy_automl.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mautoml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/diabetic_retinopathy_automl.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('./models/diabetic_retinopathy_automl.pkl', 'rb') as f:\n",
    "    automl = pickle.load(f)\n",
    "\n",
    "automl.show_models()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "model = sklearn.ensemble.RandomForestClassifier(n_estimators=100, n_jobs=5, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7083333333333334"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 2/5] END ....................C=0.1, gamma=1;, score=0.532 total time=   0.5s\n",
      "[CV 5/5] END ....................C=0.1, gamma=1;, score=0.529 total time=   0.4s\n",
      "[CV 3/5] END ....................C=0.1, gamma=1;, score=0.532 total time=   0.5s\n",
      "[CV 4/5] END ....................C=0.1, gamma=1;, score=0.529 total time=   0.4s\n",
      "[CV 1/5] END ....................C=0.1, gamma=1;, score=0.532 total time=   0.8s\n",
      "[CV 2/5] END ..................C=0.1, gamma=0.1;, score=0.532 total time=   0.4s\n",
      "[CV 1/5] END ..................C=0.1, gamma=0.1;, score=0.532 total time=   0.6s\n",
      "[CV 3/5] END ..................C=0.1, gamma=0.1;, score=0.532 total time=   0.5s\n",
      "[CV 4/5] END ..................C=0.1, gamma=0.1;, score=0.529 total time=   0.5s\n",
      "[CV 2/5] END .................C=0.1, gamma=0.01;, score=0.532 total time=   0.4s\n",
      "[CV 4/5] END .................C=0.1, gamma=0.01;, score=0.529 total time=   0.3s[CV 1/5] END .................C=0.1, gamma=0.01;, score=0.532 total time=   0.5s\n",
      "\n",
      "[CV 5/5] END ..................C=0.1, gamma=0.1;, score=0.529 total time=   0.6s\n",
      "[CV 3/5] END .................C=0.1, gamma=0.01;, score=0.532 total time=   0.5s\n",
      "[CV 1/5] END ................C=0.1, gamma=0.001;, score=0.647 total time=   0.3s\n",
      "[CV 3/5] END ................C=0.1, gamma=0.001;, score=0.682 total time=   0.3s\n",
      "[CV 2/5] END ................C=0.1, gamma=0.001;, score=0.636 total time=   0.3s\n",
      "[CV 5/5] END .................C=0.1, gamma=0.01;, score=0.529 total time=   0.5s\n",
      "[CV 4/5] END ................C=0.1, gamma=0.001;, score=0.692 total time=   0.4s\n",
      "[CV 1/5] END ...............C=0.1, gamma=0.0001;, score=0.618 total time=   0.3s\n",
      "[CV 2/5] END ...............C=0.1, gamma=0.0001;, score=0.636 total time=   0.3s\n",
      "[CV 5/5] END ................C=0.1, gamma=0.001;, score=0.599 total time=   0.3s\n",
      "[CV 3/5] END ...............C=0.1, gamma=0.0001;, score=0.601 total time=   0.3s\n",
      "[CV 2/5] END ......................C=1, gamma=1;, score=0.532 total time=   0.3s\n",
      "[CV 4/5] END ...............C=0.1, gamma=0.0001;, score=0.686 total time=   0.5s[CV 5/5] END ...............C=0.1, gamma=0.0001;, score=0.628 total time=   0.4s\n",
      "\n",
      "[CV 1/5] END ......................C=1, gamma=1;, score=0.532 total time=   0.4s\n",
      "[CV 3/5] END ......................C=1, gamma=1;, score=0.532 total time=   0.4s\n",
      "[CV 4/5] END ......................C=1, gamma=1;, score=0.529 total time=   0.4s\n",
      "[CV 5/5] END ......................C=1, gamma=1;, score=0.529 total time=   0.5s\n",
      "[CV 2/5] END ....................C=1, gamma=0.1;, score=0.538 total time=   0.5s\n",
      "[CV 3/5] END ....................C=1, gamma=0.1;, score=0.514 total time=   0.5s\n",
      "[CV 1/5] END ....................C=1, gamma=0.1;, score=0.561 total time=   0.8s\n",
      "[CV 4/5] END ....................C=1, gamma=0.1;, score=0.529 total time=   0.5s\n",
      "[CV 1/5] END ...................C=1, gamma=0.01;, score=0.618 total time=   0.4s\n",
      "[CV 5/5] END ....................C=1, gamma=0.1;, score=0.535 total time=   0.5s\n",
      "[CV 2/5] END ...................C=1, gamma=0.01;, score=0.607 total time=   0.4s\n",
      "[CV 3/5] END ...................C=1, gamma=0.01;, score=0.624 total time=   0.4s\n",
      "[CV 4/5] END ...................C=1, gamma=0.01;, score=0.657 total time=   0.2s\n",
      "[CV 1/5] END ..................C=1, gamma=0.001;, score=0.676 total time=   0.2s\n",
      "[CV 2/5] END ..................C=1, gamma=0.001;, score=0.676 total time=   0.2s\n",
      "[CV 4/5] END ..................C=1, gamma=0.001;, score=0.733 total time=   0.3s\n",
      "[CV 5/5] END ..................C=1, gamma=0.001;, score=0.657 total time=   0.3s\n",
      "[CV 5/5] END ...................C=1, gamma=0.01;, score=0.610 total time=   0.5s\n",
      "[CV 3/5] END ..................C=1, gamma=0.001;, score=0.694 total time=   0.4s\n",
      "[CV 2/5] END .................C=1, gamma=0.0001;, score=0.671 total time=   0.2s\n",
      "[CV 3/5] END .................C=1, gamma=0.0001;, score=0.694 total time=   0.2s\n",
      "[CV 1/5] END .................C=1, gamma=0.0001;, score=0.647 total time=   0.4s\n",
      "[CV 5/5] END .................C=1, gamma=0.0001;, score=0.698 total time=   0.2s\n",
      "[CV 4/5] END .................C=1, gamma=0.0001;, score=0.721 total time=   0.3s\n",
      "[CV 3/5] END .....................C=10, gamma=1;, score=0.532 total time=   0.3s\n",
      "[CV 1/5] END .....................C=10, gamma=1;, score=0.532 total time=   0.3s\n",
      "[CV 2/5] END .....................C=10, gamma=1;, score=0.532 total time=   0.3s\n",
      "[CV 5/5] END .....................C=10, gamma=1;, score=0.529 total time=   0.3s\n",
      "[CV 4/5] END .....................C=10, gamma=1;, score=0.529 total time=   0.4s\n",
      "[CV 2/5] END ...................C=10, gamma=0.1;, score=0.555 total time=   0.3s\n",
      "[CV 1/5] END ...................C=10, gamma=0.1;, score=0.566 total time=   0.4s\n",
      "[CV 3/5] END ...................C=10, gamma=0.1;, score=0.514 total time=   0.3s\n",
      "[CV 4/5] END ...................C=10, gamma=0.1;, score=0.541 total time=   0.4s\n",
      "[CV 2/5] END ..................C=10, gamma=0.01;, score=0.607 total time=   0.4s\n",
      "[CV 1/5] END ..................C=10, gamma=0.01;, score=0.647 total time=   0.6s\n",
      "[CV 5/5] END ...................C=10, gamma=0.1;, score=0.512 total time=   0.8s\n",
      "[CV 3/5] END ..................C=10, gamma=0.01;, score=0.647 total time=   0.8s\n",
      "[CV 4/5] END ..................C=10, gamma=0.01;, score=0.651 total time=   0.7s\n",
      "[CV 1/5] END .................C=10, gamma=0.001;, score=0.659 total time=   0.4s\n",
      "[CV 5/5] END ..................C=10, gamma=0.01;, score=0.587 total time=   0.6s\n",
      "[CV 2/5] END .................C=10, gamma=0.001;, score=0.671 total time=   0.4s\n",
      "[CV 1/5] END ................C=10, gamma=0.0001;, score=0.688 total time=   0.3s\n",
      "[CV 5/5] END .................C=10, gamma=0.001;, score=0.674 total time=   0.4s\n",
      "[CV 3/5] END .................C=10, gamma=0.001;, score=0.728 total time=   0.6s\n",
      "[CV 4/5] END .................C=10, gamma=0.001;, score=0.680 total time=   0.5s\n",
      "[CV 2/5] END ................C=10, gamma=0.0001;, score=0.734 total time=   0.4s\n",
      "[CV 3/5] END ................C=10, gamma=0.0001;, score=0.682 total time=   0.3s[CV 4/5] END ................C=10, gamma=0.0001;, score=0.767 total time=   0.2s\n",
      "\n",
      "[CV 5/5] END ................C=10, gamma=0.0001;, score=0.715 total time=   0.4s\n",
      "[CV 2/5] END ....................C=100, gamma=1;, score=0.532 total time=   0.5s\n",
      "[CV 1/5] END ....................C=100, gamma=1;, score=0.532 total time=   0.7s\n",
      "[CV 4/5] END ....................C=100, gamma=1;, score=0.529 total time=   0.6s\n",
      "[CV 3/5] END ....................C=100, gamma=1;, score=0.532 total time=   0.7s\n",
      "[CV 5/5] END ....................C=100, gamma=1;, score=0.529 total time=   0.6s\n",
      "[CV 1/5] END ..................C=100, gamma=0.1;, score=0.566 total time=   0.5s\n",
      "[CV 2/5] END ..................C=100, gamma=0.1;, score=0.555 total time=   0.6s\n",
      "[CV 3/5] END ..................C=100, gamma=0.1;, score=0.514 total time=   0.6s\n",
      "[CV 4/5] END ..................C=100, gamma=0.1;, score=0.541 total time=   0.6s\n",
      "[CV 5/5] END ..................C=100, gamma=0.1;, score=0.512 total time=   0.6s\n",
      "[CV 1/5] END .................C=100, gamma=0.01;, score=0.647 total time=   0.5s\n",
      "[CV 2/5] END .................C=100, gamma=0.01;, score=0.578 total time=   0.4s\n",
      "[CV 3/5] END .................C=100, gamma=0.01;, score=0.647 total time=   0.4s\n",
      "[CV 4/5] END .................C=100, gamma=0.01;, score=0.645 total time=   0.5s\n",
      "[CV 5/5] END .................C=100, gamma=0.01;, score=0.576 total time=   0.5s\n",
      "[CV 2/5] END ................C=100, gamma=0.001;, score=0.665 total time=   0.4s\n",
      "[CV 1/5] END ................C=100, gamma=0.001;, score=0.624 total time=   0.5s\n",
      "[CV 3/5] END ................C=100, gamma=0.001;, score=0.711 total time=   0.6s\n",
      "[CV 1/5] END ...............C=100, gamma=0.0001;, score=0.688 total time=   0.3s[CV 2/5] END ...............C=100, gamma=0.0001;, score=0.763 total time=   0.3s\n",
      "\n",
      "[CV 4/5] END ................C=100, gamma=0.001;, score=0.674 total time=   0.6s\n",
      "[CV 5/5] END ................C=100, gamma=0.001;, score=0.680 total time=   0.5s\n",
      "[CV 3/5] END ...............C=100, gamma=0.0001;, score=0.740 total time=   0.4s\n",
      "[CV 5/5] END ...............C=100, gamma=0.0001;, score=0.773 total time=   0.3s\n",
      "[CV 4/5] END ...............C=100, gamma=0.0001;, score=0.762 total time=   0.3s\n",
      "[CV 1/5] END ...................C=1000, gamma=1;, score=0.532 total time=   0.3s\n",
      "[CV 2/5] END ...................C=1000, gamma=1;, score=0.532 total time=   0.4s\n",
      "[CV 3/5] END ...................C=1000, gamma=1;, score=0.532 total time=   0.4s\n",
      "[CV 1/5] END .................C=1000, gamma=0.1;, score=0.566 total time=   0.4s\n",
      "[CV 5/5] END ...................C=1000, gamma=1;, score=0.529 total time=   0.5s\n",
      "[CV 4/5] END ...................C=1000, gamma=1;, score=0.529 total time=   0.5s\n",
      "[CV 2/5] END .................C=1000, gamma=0.1;, score=0.555 total time=   0.5s\n",
      "[CV 3/5] END .................C=1000, gamma=0.1;, score=0.514 total time=   0.5s\n",
      "[CV 5/5] END .................C=1000, gamma=0.1;, score=0.512 total time=   0.6s\n",
      "[CV 1/5] END ................C=1000, gamma=0.01;, score=0.647 total time=   0.5s\n",
      "[CV 4/5] END .................C=1000, gamma=0.1;, score=0.541 total time=   0.7s\n",
      "[CV 2/5] END ................C=1000, gamma=0.01;, score=0.578 total time=   0.5s\n",
      "[CV 3/5] END ................C=1000, gamma=0.01;, score=0.647 total time=   0.5s\n",
      "[CV 4/5] END ................C=1000, gamma=0.01;, score=0.645 total time=   0.5s\n",
      "[CV 5/5] END ................C=1000, gamma=0.01;, score=0.576 total time=   0.5s\n",
      "[CV 1/5] END ...............C=1000, gamma=0.001;, score=0.642 total time=   1.2s\n",
      "[CV 3/5] END ...............C=1000, gamma=0.001;, score=0.699 total time=   1.2s\n",
      "[CV 5/5] END ...............C=1000, gamma=0.001;, score=0.680 total time=   1.2s\n",
      "[CV 2/5] END ...............C=1000, gamma=0.001;, score=0.647 total time=   1.6s\n",
      "[CV 4/5] END ...............C=1000, gamma=0.001;, score=0.663 total time=   1.2s\n",
      "[CV 1/5] END ..............C=1000, gamma=0.0001;, score=0.676 total time=   1.3s\n",
      "[CV 2/5] END ..............C=1000, gamma=0.0001;, score=0.746 total time=   1.5s\n",
      "[CV 5/5] END ..............C=1000, gamma=0.0001;, score=0.773 total time=   1.4s\n",
      "[CV 3/5] END ..............C=1000, gamma=0.0001;, score=0.723 total time=   1.5s\n",
      "[CV 4/5] END ..............C=1000, gamma=0.0001;, score=0.762 total time=   1.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(probability=True, random_state=42), n_jobs=5,\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.svm\n",
    "import sklearn.model_selection\n",
    "\n",
    "model = sklearn.svm.SVC(random_state=42, probability=True)\n",
    "params = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001]}\n",
    "gridSearch = sklearn.model_selection.GridSearchCV(model, param_grid=params, cv=5, n_jobs=5, verbose=3)\n",
    "gridSearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78125"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = gridSearch.predict(X_test)\n",
    "sklearn.metrics.accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./models/diabetic_retinopathy_gridsearch.pkl', 'wb') as f:\n",
    "    pickle.dump(gridSearch, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./models/diabetic_retinopathy_gridsearch.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_features = range(2, 18)\n",
    "categorical_features = X_train.columns.drop(continous_features).tolist()\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X_train.columns.tolist(), class_names=['No Sign', 'Sign'], categorical_features=categorical_features, discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1127.284937620163 seconds ---\n",
      "--- 960.6424679756165 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from lime import submodular_pick\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "exp1 = submodular_pick.SubmodularPick(explainer, X_test.values, model.predict_proba, sample_size=200, num_features=len(X_test.columns), num_exps_desired=5)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "exp2 = submodular_pick.SubmodularPick(explainer, X_test.values, model.predict_proba, sample_size=200, num_features=len(X_test.columns), num_exps_desired=5)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_imp(sp_obj):\n",
    "    W_pick=pd.DataFrame([dict(this.as_list(this.available_labels()[0])) for this in sp_obj.sp_explanations]).fillna(0)\n",
    "    W_pick['prediction'] = [this.available_labels()[0] for this in sp_obj.sp_explanations]\n",
    "    W=pd.DataFrame([dict(this.as_list(this.available_labels()[0])) for this in sp_obj.explanations]).fillna(0)\n",
    "    W['prediction'] = [this.available_labels()[0] for this in sp_obj.explanations]\n",
    "    np.abs(W.drop(\"prediction\", axis=1)).mean(axis=0).sort_values(ascending=False).head(25).sort_values(ascending=True)\n",
    "    grped_coeff = W.groupby(\"prediction\").mean()\n",
    "    grped_coeff = grped_coeff.T\n",
    "    return grped_coeff[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp1 = get_feature_imp(exp1)\n",
    "feat_imp2 = get_feature_imp(exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.60797109e-02, -2.01083119e-02, -1.70482272e-02,  1.46429187e-03,\n",
       "       -6.32766909e-03,  1.81562623e-03,  1.51379486e-04,  1.38767756e-03,\n",
       "        4.24616947e-03, -3.71446214e-03, -1.40072010e-03, -4.16453260e-05,\n",
       "        1.81055206e-02,  3.49338689e-04, -5.66418899e-04,  6.47858382e-04,\n",
       "       -2.25833312e-03, -3.96235525e-07,  2.33639522e-04, -5.61476437e-02,\n",
       "        2.74452802e-02,  9.59484416e-03,  7.31199534e-03,  5.89873102e-03,\n",
       "        1.67762235e-02, -1.82812425e-04, -2.25993322e-03,  6.27170052e-05,\n",
       "       -3.28158549e-05,  9.96064090e-04,  7.16737691e-04, -5.60762135e-02,\n",
       "        1.00775398e-02,  1.23579753e-02,  6.14072807e-03, -7.26686503e-05,\n",
       "       -1.41755661e-03,  3.41798980e-03,  2.92800781e-03, -3.80682543e-03,\n",
       "        2.35768074e-03,  6.63435142e-04,  5.30753575e-04, -6.97393084e-04,\n",
       "       -4.91630779e-03,  8.10373113e-04, -5.00869188e-04,  3.05297337e-01,\n",
       "       -1.02423374e-01, -3.84658219e-02, -2.05085549e-02, -2.72911271e-02,\n",
       "       -8.38089714e-05, -7.69303050e-03,  5.99486324e-03, -5.37041795e-03,\n",
       "       -4.27730581e-04,  4.13792868e-04,  2.01270727e-03, -8.46144025e-06,\n",
       "        2.34045609e-04,  5.86197344e-04,  1.55768728e-03,  3.36033450e-03,\n",
       "       -3.00990419e-04, -5.73127608e-03,  1.22540758e-03,  5.00980320e-04])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_identity(feat_imp1, feat_imp2):\n",
    "    sum = 0\n",
    "    for i in range(len(feat_imp1)):\n",
    "        if(feat_imp1[i] == feat_imp2[i]):\n",
    "            sum += 1\n",
    "    return sum/len(feat_imp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = global_identity(feat_imp1, feat_imp2)\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_fi(feat_imp):\n",
    "    return np.abs(feat_imp) / np.sum(np.abs(feat_imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_feat_imp = normal_fi(feat_imp1 + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entropy Ratio\n",
    "Ser = np.sum(normal_feat_imp*np.log(normal_feat_imp))/np.log(1/len(normal_feat_imp))\n",
    "\n",
    "# Kullback-Leibler Divergence\n",
    "Skl = np.sum(normal_feat_imp*np.log(normal_feat_imp/(1/len(normal_feat_imp))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gini(pfi):\n",
    "    sum = 0\n",
    "    for i in range(len(pfi)):\n",
    "        sum_curr = 0\n",
    "        for j in range(len(pfi)):\n",
    "            sum_curr += np.abs(pfi[i]-pfi[j])\n",
    "        sum += sum_curr\n",
    "    \n",
    "    return sum/(2*len(pfi)**2)*(np.sum(pfi)/len(pfi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sg = calc_gini(normal_feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6373754076886349, 1.530097261344149, 0.00017553587383214452)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ser, Skl, Sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_alpha_fi(normal_pfi, alpha):\n",
    "    j_inst = 0\n",
    "    sum = 0\n",
    "    for i in range(len(normal_pfi)-1, -1, -1):\n",
    "        sum += normal_pfi[i]\n",
    "        if sum<=alpha:\n",
    "            j_inst = i\n",
    "        else:\n",
    "            break\n",
    "    return 1- (j_inst/len(normal_pfi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7058823529411764"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_alpha_fi(normal_feat_imp, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_imp_all(sp_obj):\n",
    "    W_pick=pd.DataFrame([dict(this.as_list(this.available_labels()[0])) for this in sp_obj.sp_explanations]).fillna(0)\n",
    "    W_pick['prediction'] = [this.available_labels()[0] for this in sp_obj.sp_explanations]\n",
    "    W=pd.DataFrame([dict(this.as_list(this.available_labels()[0])) for this in sp_obj.explanations]).fillna(0)\n",
    "    W['prediction'] = [this.available_labels()[0] for this in sp_obj.explanations]\n",
    "    np.abs(W.drop(\"prediction\", axis=1)).mean(axis=0).sort_values(ascending=False).head(25).sort_values(ascending=True)\n",
    "    grped_coeff = W.groupby(\"prediction\").mean()\n",
    "    grped_coeff = grped_coeff.T\n",
    "    return grped_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_feat_imp, class2_feat_imp = get_feature_imp_all(exp1)[0].values, get_feature_imp_all(exp1)[1].values\n",
    "normal_class1_fi, normal_class2_fi = normal_fi(class1_feat_imp), normal_fi(class2_feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36539163769093935"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(normal_class1_fi - normal_class2_fi, ord=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ciu import determine_ciu\n",
    "import tqdm\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_exp(exp, feature_num):\n",
    "    enc_exp = np.zeros((len(exp),feature_num))\n",
    "    for i in range(len(exp)):\n",
    "        for j in range(len(exp[i])):\n",
    "            enc_exp[i][int(exp[i,j,0])] = exp[i,j,1]\n",
    "    return enc_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_fn_blk(xtest):\n",
    "    exp1 = []\n",
    "    for i in tqdm.tqdm(range(len(xtest))):\n",
    "        exp = determine_ciu(X_test.iloc[i:i+1], model.predict_proba, X_train.to_dict('list'), samples = 1000, prediction_index = 1)\n",
    "        exp_list = [[feat_list.index(i), exp.ci[i]] for i in exp.ci]\n",
    "        exp1.append(exp_list)\n",
    "    return np.array(exp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 288/288 [08:56<00:00,  1.86s/it]\n",
      "100%|██████████| 288/288 [09:33<00:00,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "exp1 = exp_fn_blk(X_test)\n",
    "exp2 = exp_fn_blk(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./explanations/diabetic_retinopathy_ciu1.npy', exp1)\n",
    "np.save('./explanations/diabetic_retinopathy_ciu2.npy', exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krish/anaconda3/envs/interpret/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py:984: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  self._check_params(X)\n"
     ]
    }
   ],
   "source": [
    "i = metrics.calc_identity(exp1, exp2)\n",
    "s = metrics.calc_separability(exp1)\n",
    "enc1 = enc_exp(exp1, len(feat_list))\n",
    "sb = metrics.calc_stability(enc1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100.0, 0, 288), (0, 288, 82944, 0.0), (95, 288))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i, s, sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm = metrics.normalize_test(X_train, X_test)\n",
    "sim = metrics.calc_similarity(exp1, X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9352786077097661"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/288 [00:01<00:46,  6.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 288/288 [00:24<00:00, 11.76it/s]\n"
     ]
    }
   ],
   "source": [
    "list_monotonicity = []\n",
    "list_non_sensitivity = []\n",
    "list_effective_complexity = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(X_test))):\n",
    "    atr = exp1[i]\n",
    "    sorted_atr = [j for i,j in atr]\n",
    "    sorted_feat = [i for i,j in atr]\n",
    "    y = np.zeros(2, dtype=int)\n",
    "    np.put(y, y_test.iloc[i], 1)\n",
    "    example = metrics.FeatureAttribution(model, X_test.to_numpy()[i], y, sorted_atr)\n",
    "    list_monotonicity.append(example.monotonicity())\n",
    "    list_non_sensitivity.append(example.non_sensitivity())\n",
    "    list_effective_complexity.append(example.effective_complexity(sorted_feat, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.053242724289966445\n",
      "0.013888888888888888\n",
      "5.461805555555555\n",
      "-0.08333333333333334\n",
      "0.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(list_monotonicity))\n",
    "print(np.mean(list_non_sensitivity))\n",
    "print(np.mean(list_effective_complexity))\n",
    "\n",
    "print(np.median(list_monotonicity))\n",
    "print(np.median(list_non_sensitivity))\n",
    "print(np.median(list_effective_complexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 17/288 [00:00<00:16, 16.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 288/288 [00:11<00:00, 24.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3229166666666667"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.calc_trust_score(model, X_test.to_numpy(), exp1, 3, X_train.columns.to_list())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RULEFIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrules import SkopeRules\n",
    "import metrics_rules\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dataset column names to x0, x1, x2, ...\n",
    "X_train.columns = ['x'+str(i) for i in range(len(X_train.columns))]\n",
    "X_test.columns = ['x'+str(i) for i in range(len(X_test.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SkopeRules(max_depth_duplication=2,\n",
    "                    n_estimators=512,\n",
    "                    precision_min=0.3,\n",
    "                    recall_min=0.1,\n",
    "                    feature_names=X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 20.400280237197876 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.07584309577941895 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "top_rules1 = clf.score_top_rules(X_test)\n",
    "top_rules2 = clf.score_top_rules(X_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 288, 288)\n",
      "(30466, 288, 82944, 36.730806327160494)\n",
      "(109, 288)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krish/anaconda3/envs/interpret/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py:984: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  self._check_params(X)\n"
     ]
    }
   ],
   "source": [
    "i = metrics_rules.calc_identity_rules(top_rules1, top_rules2)\n",
    "print(i)\n",
    "\n",
    "s = metrics_rules.calc_separability_rules(top_rules1)\n",
    "print(s)\n",
    "\n",
    "enc_rules = metrics_rules.exp_enc(clf, top_rules1)\n",
    "sb = metrics_rules.calc_stability_rules(enc_rules, y_test)\n",
    "print(sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8747086026218248\n"
     ]
    }
   ],
   "source": [
    "X_test_norm = metrics_rules.normalize_test(X_train, X_test)\n",
    "sim = metrics_rules.calc_similarity(enc_rules, X_test_norm)\n",
    "print(sim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RULEMATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = range(2, 18)\n",
    "categorical_features = X_train.columns.drop(continuous_features).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rulematrix\n",
    "import time\n",
    "import metrics_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_continuous = [True if i in continuous_features else False for i in X_train.columns.tolist()]\n",
    "is_categorical = [True if i in categorical_features else False for i in X_train.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = rulematrix.surrogate.rule_surrogate(\n",
    "    model.predict,\n",
    "    X_train,\n",
    "    sampling_rate=4,\n",
    "    is_continuous=is_continuous,\n",
    "    is_categorical=is_categorical,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_fn_blk(xtest):\n",
    "    exp1 = []\n",
    "    for i in range(len(xtest)):\n",
    "        queried_rules = np.arange(surrogate.student.n_rules)[surrogate.student.decision_path(test_x[i].reshape(1,-1)).reshape(-1)]\n",
    "        exp1.append(queried_rules[-1])\n",
    "    return np.array(exp1)\n",
    "exp_fn_wrap = lambda x: np.array(exp_fn_blk(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.1182096004486084 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "exp1 = exp_fn_blk(test_x)\n",
    "exp2 = exp_fn_blk(test_x)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_exp(exp, n_features):\n",
    "    enc = []\n",
    "    for i in range(exp.shape[0]):\n",
    "        new = np.zeros(n_features)\n",
    "        for j in surrogate.student.rule_list[exp[i]].clauses:\n",
    "            new[j.feature_idx] = 1\n",
    "        enc.append(new)\n",
    "    return np.array(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_exp = enc_exp(exp1, X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 288, 288)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8556, 288, 82944, 10.315393518518519)\n",
      "(119, 288)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krish/anaconda3/envs/interpret/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py:984: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  self._check_params(X)\n"
     ]
    }
   ],
   "source": [
    "i = metrics_rules.calc_identity_rules(exp1, exp2)\n",
    "print(i)\n",
    "\n",
    "s = metrics_rules.calc_separability_rules(exp1)\n",
    "print(s)\n",
    "\n",
    "sb = metrics_rules.calc_stability_rules(enc_exp, y_test)\n",
    "print(sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm = metrics_rules.normalize_test(X_train, X_test)\n",
    "sim = metrics_rules.calc_similarity(enc_exp, X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.330881702767274"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANCHOR Global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anchor import anchor_tabular\n",
    "import anchor_utils\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "    y_train.unique().tolist(),\n",
    "    X_train.columns.tolist(),\n",
    "    X_train.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance using Anchor\n",
    "def calc_fi(X_test, model, explainer):\n",
    "    all_exps = []\n",
    "    for i in tqdm.tqdm(range(len(X_test))):\n",
    "        exp = explainer.explain_instance(X_test.values[i], model.predict, threshold=0.95)\n",
    "        all_exps.append(exp.exp_map)\n",
    "    fi = anchor_utils.greedy_pick_anchor(all_exps, X_test.values, k = len(X_test.columns))\n",
    "    return fi\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 288/288 [03:26<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.041666666666666664\n",
      "1 0.07291666666666667\n",
      "2 0.10069444444444445\n",
      "3 0.125\n",
      "4 0.14930555555555555\n",
      "5 0.1701388888888889\n",
      "6 0.1909722222222222\n",
      "7 0.20833333333333334\n",
      "8 0.2222222222222222\n",
      "9 0.2361111111111111\n",
      "10 0.25\n",
      "11 0.2638888888888889\n",
      "12 0.2777777777777778\n",
      "13 0.2916666666666667\n",
      "14 0.3020833333333333\n",
      "15 0.3090277777777778\n",
      "16 0.3159722222222222\n",
      "17 0.3229166666666667\n",
      "18 0.3298611111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 288/288 [04:14<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.041666666666666664\n",
      "1 0.07291666666666667\n",
      "2 0.10069444444444445\n",
      "3 0.125\n",
      "4 0.14930555555555555\n",
      "5 0.1701388888888889\n",
      "6 0.1909722222222222\n",
      "7 0.21180555555555555\n",
      "8 0.22569444444444445\n",
      "9 0.23958333333333334\n",
      "10 0.2534722222222222\n",
      "11 0.2638888888888889\n",
      "12 0.2743055555555556\n",
      "13 0.2847222222222222\n",
      "14 0.2951388888888889\n",
      "15 0.3020833333333333\n",
      "16 0.3090277777777778\n",
      "17 0.3159722222222222\n",
      "18 0.3229166666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exp1 = calc_fi(X_test, model, explainer)\n",
    "exp2 = calc_fi(X_test, model, explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_fi(feat_imp):\n",
    "    feat_imp = np.array(feat_imp) + 1e-9\n",
    "    return np.abs(feat_imp) / np.sum(np.abs(feat_imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_feat_imp1 = normal_fi(exp1)\n",
    "normal_feat_imp2 = normal_fi(exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def global_identity(feat_imp1, feat_imp2):\n",
    "    sum = 0\n",
    "    for i in range(len(feat_imp1)):\n",
    "        if(feat_imp1[i] == feat_imp2[i]):\n",
    "            sum += 1\n",
    "    return sum/len(feat_imp1)\n",
    "\n",
    "i = global_identity(normal_feat_imp1, normal_feat_imp2)\n",
    "i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entropy Ratio\n",
    "Ser = np.sum(normal_feat_imp1*np.log(normal_feat_imp1))/np.log(1/len(normal_feat_imp1))\n",
    "\n",
    "# Kullback-Leibler Divergence\n",
    "Skl = np.sum(normal_feat_imp1*np.log(normal_feat_imp1/(1/len(normal_feat_imp1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gini(pfi):\n",
    "    sum = 0\n",
    "    for i in range(len(pfi)):\n",
    "        sum_curr = 0\n",
    "        for j in range(len(pfi)):\n",
    "            sum_curr += np.abs(pfi[i]-pfi[j])\n",
    "        sum += sum_curr\n",
    "    \n",
    "    return sum/(2*len(pfi)**2)*(np.sum(pfi)/len(pfi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sg = calc_gini(normal_feat_imp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9184919903354068, 0.23999536077070274, 0.0010646372628182186)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ser, Skl, Sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_alpha_fi(normal_pfi, alpha):\n",
    "    j_inst = 0\n",
    "    sum = 0\n",
    "    for i in range(len(normal_pfi)-1, -1, -1):\n",
    "        sum += normal_pfi[i]\n",
    "        if sum<=alpha:\n",
    "            j_inst = i\n",
    "        else:\n",
    "            break\n",
    "    return 1- (j_inst/len(normal_pfi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.736842105263158"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_alpha_fi(normal_feat_imp1, 0.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
