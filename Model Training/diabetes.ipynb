{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../Datasets/Diabetes/diabetic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.replace('?', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['weight','payer_code','medical_specialty'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['encounter_id','patient_nbr','admission_type_id','discharge_disposition_id','admission_source_id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>...</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[50-60)</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101761</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Male</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Down</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101762</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[80-90)</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101763</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Down</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101764</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[80-90)</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101765</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98053 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   race  gender      age  time_in_hospital  \\\n",
       "1             Caucasian  Female  [10-20)                 3   \n",
       "2       AfricanAmerican  Female  [20-30)                 2   \n",
       "3             Caucasian    Male  [30-40)                 2   \n",
       "4             Caucasian    Male  [40-50)                 1   \n",
       "5             Caucasian    Male  [50-60)                 3   \n",
       "...                 ...     ...      ...               ...   \n",
       "101761  AfricanAmerican    Male  [70-80)                 3   \n",
       "101762  AfricanAmerican  Female  [80-90)                 5   \n",
       "101763        Caucasian    Male  [70-80)                 1   \n",
       "101764        Caucasian  Female  [80-90)                10   \n",
       "101765        Caucasian    Male  [70-80)                 6   \n",
       "\n",
       "        num_lab_procedures  num_procedures  num_medications  \\\n",
       "1                       59               0               18   \n",
       "2                       11               5               13   \n",
       "3                       44               1               16   \n",
       "4                       51               0                8   \n",
       "5                       31               6               16   \n",
       "...                    ...             ...              ...   \n",
       "101761                  51               0               16   \n",
       "101762                  33               3               18   \n",
       "101763                  53               0                9   \n",
       "101764                  45               2               21   \n",
       "101765                  13               3                3   \n",
       "\n",
       "        number_outpatient  number_emergency  number_inpatient  ...  \\\n",
       "1                       0                 0                 0  ...   \n",
       "2                       2                 0                 1  ...   \n",
       "3                       0                 0                 0  ...   \n",
       "4                       0                 0                 0  ...   \n",
       "5                       0                 0                 0  ...   \n",
       "...                   ...               ...               ...  ...   \n",
       "101761                  0                 0                 0  ...   \n",
       "101762                  0                 0                 1  ...   \n",
       "101763                  1                 0                 0  ...   \n",
       "101764                  0                 0                 1  ...   \n",
       "101765                  0                 0                 0  ...   \n",
       "\n",
       "       citoglipton insulin glyburide-metformin  glipizide-metformin  \\\n",
       "1               No      Up                  No                   No   \n",
       "2               No      No                  No                   No   \n",
       "3               No      Up                  No                   No   \n",
       "4               No  Steady                  No                   No   \n",
       "5               No  Steady                  No                   No   \n",
       "...            ...     ...                 ...                  ...   \n",
       "101761          No    Down                  No                   No   \n",
       "101762          No  Steady                  No                   No   \n",
       "101763          No    Down                  No                   No   \n",
       "101764          No      Up                  No                   No   \n",
       "101765          No      No                  No                   No   \n",
       "\n",
       "       glimepiride-pioglitazone metformin-rosiglitazone  \\\n",
       "1                            No                      No   \n",
       "2                            No                      No   \n",
       "3                            No                      No   \n",
       "4                            No                      No   \n",
       "5                            No                      No   \n",
       "...                         ...                     ...   \n",
       "101761                       No                      No   \n",
       "101762                       No                      No   \n",
       "101763                       No                      No   \n",
       "101764                       No                      No   \n",
       "101765                       No                      No   \n",
       "\n",
       "       metformin-pioglitazone change diabetesMed readmitted  \n",
       "1                          No     Ch         Yes        >30  \n",
       "2                          No     No         Yes         NO  \n",
       "3                          No     Ch         Yes         NO  \n",
       "4                          No     Ch         Yes         NO  \n",
       "5                          No     No         Yes        >30  \n",
       "...                       ...    ...         ...        ...  \n",
       "101761                     No     Ch         Yes        >30  \n",
       "101762                     No     No         Yes         NO  \n",
       "101763                     No     Ch         Yes         NO  \n",
       "101764                     No     Ch         Yes         NO  \n",
       "101765                     No     No          No         NO  \n",
       "\n",
       "[98053 rows x 42 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[dataset.age== '[0-10)','age'] = 0;\n",
    "dataset.loc[dataset.age== '[10-20)','age'] = 10;\n",
    "dataset.loc[dataset.age== '[20-30)','age'] = 20;\n",
    "dataset.loc[dataset.age== '[30-40)','age'] = 30;\n",
    "dataset.loc[dataset.age== '[40-50)','age'] = 40;\n",
    "dataset.loc[dataset.age== '[50-60)','age'] = 50;\n",
    "dataset.loc[dataset.age== '[60-70)','age'] = 60;\n",
    "dataset.loc[dataset.age== '[70-80)','age'] = 70;\n",
    "dataset.loc[dataset.age== '[80-90)','age'] = 80;\n",
    "dataset.loc[dataset.age== '[90-100)','age'] = 90;\n",
    "dataset.age = dataset.age.astype(np.int32)\n",
    "\n",
    "\n",
    "dataset.loc[dataset.max_glu_serum== 'None','max_glu_serum'] = 0;\n",
    "dataset.loc[dataset.max_glu_serum== 'Norm','max_glu_serum'] = 100;\n",
    "dataset.loc[dataset.max_glu_serum== '>200','max_glu_serum'] = 200;\n",
    "dataset.loc[dataset.max_glu_serum== '>300','max_glu_serum'] = 300;\n",
    "dataset.max_glu_serum = dataset.max_glu_serum.astype(np.int32)\n",
    "\n",
    "\n",
    "dataset.loc[dataset.A1Cresult== 'None','A1Cresult'] = 0;\n",
    "dataset.loc[dataset.A1Cresult== 'Norm','A1Cresult'] = 5;\n",
    "dataset.loc[dataset.A1Cresult== '>7','A1Cresult'] = 7;\n",
    "dataset.loc[dataset.A1Cresult== '>8','A1Cresult'] = 8;\n",
    "dataset.A1Cresult = dataset.A1Cresult.astype(np.int32)\n",
    "\n",
    "\n",
    "dataset.loc[dataset.change== 'No','change'] = 0;\n",
    "dataset.loc[dataset.change== 'Ch','change'] = 1;\n",
    "dataset.change = dataset.change.astype(np.int8)\n",
    "\n",
    "\n",
    "\n",
    "dataset.loc[dataset.diabetesMed== 'No','diabetesMed'] = 0;\n",
    "dataset.loc[dataset.diabetesMed== 'Yes','diabetesMed'] = 1;\n",
    "dataset.diabetesMed = dataset.diabetesMed.astype(np.int8)\n",
    "\n",
    "\n",
    "medications = [\"metformin\", \"repaglinide\", \"nateglinide\", \"chlorpropamide\", \"glimepiride\", \"acetohexamide\", \"glipizide\", \"glyburide\", \"tolbutamide\", \"pioglitazone\", \"rosiglitazone\", \"acarbose\", \"miglitol\", \"troglitazone\", \"tolazamide\", \"examide\", \"citoglipton\", \"insulin\", \"glyburide-metformin\", \"glipizide-metformin\", \"glimepiride-pioglitazone\", \"metformin-rosiglitazone\", \"metformin-pioglitazone\"]\n",
    "\n",
    "for med in medications:\n",
    "    dataset.loc[dataset[med] == 'No', med] = -20;\n",
    "    dataset.loc[dataset[med] == 'Down', med] = -10;\n",
    "    dataset.loc[dataset[med] == 'Steady', med] = 0;\n",
    "    dataset.loc[dataset[med] == 'Up', med] = 10;\n",
    "    dataset[med] = dataset[med].astype(np.int32)\n",
    "    \n",
    "\n",
    "categoricals = ['race', 'gender', 'diag_1', 'diag_2', 'diag_3']\n",
    "\n",
    "\n",
    "\n",
    "for c in categoricals:\n",
    "    dataset[c] = pd.Categorical(dataset[c]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[dataset.readmitted != 'NO','readmitted'] = 0\n",
    "dataset.loc[dataset.readmitted == 'NO','readmitted'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dataset.drop('readmitted', axis=1), dataset['readmitted']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2023-07-02 20:02:48,144:Client-EnsembleBuilder] No runs were available to build an ensemble from\n"
     ]
    }
   ],
   "source": [
    "automl = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=360)\n",
    "automl.fit(X_train.values, y_train)\n",
    "y_hat = automl.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62919148241821"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./models/diabetes_automl.pkl', 'wb') as f:\n",
    "    pickle.dump(automl, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('./models/diabetes_automl.pkl', 'rb') as f:\n",
    "    automl = pickle.load(f)\n",
    "\n",
    "len(automl.show_models())\n",
    "# y_hat = automl.predict(X_test.values)\n",
    "# sklearn.metrics.accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "model = sklearn.ensemble.RandomForestClassifier(n_estimators=512, n_jobs=5, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6216447744146202"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./models/diabetes_random_forest.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=SVC(random_state=42), n_jobs=5,\n",
       "             param_grid={'C': [0.1, 1, 10]}, verbose=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.svm\n",
    "import sklearn.model_selection\n",
    "\n",
    "model = sklearn.svm.SVC(random_state=42)\n",
    "params = {'C': [0.1, 1, 10]}\n",
    "gridSearch = sklearn.model_selection.GridSearchCV(model, param_grid=params, cv=2, n_jobs=5, verbose=3)\n",
    "gridSearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.584155992494085"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = gridSearch.predict(X_test)\n",
    "sklearn.metrics.accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = ['time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1', 'diag_2', 'diag_3', 'number_diagnoses']\n",
    "categorical_features = X_train.columns.drop(continuous_features).tolist()\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X_train.columns.tolist(), class_names=['Readmitted', 'Not Readmitted'], categorical_features=categorical_features, discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 0.02\n",
    "X_test_sample, _, y_test_sample, _ = train_test_split(X_test, y_test, train_size=frac, random_state=42, stratify=y_test)\n",
    "\n",
    "test_x = X_test_sample.values\n",
    "test_y = y_test_sample.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_fn = lambda i: explainer.explain_instance(test_x[i], automl.predict_proba, num_features=len(X_test.columns))\n",
    "def exp_fn_blk(xtest, exp_fn):\n",
    "    exp1 = []\n",
    "    for i in tqdm.tqdm(range(len(xtest))):\n",
    "        exp = exp_fn(i)\n",
    "        exp1.append(exp.as_map()[exp.available_labels()[0]])\n",
    "    return np.array(exp1)\n",
    "exp_fn_wrap = lambda x: np.array(exp_fn_blk(x, exp_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490/490 [38:53<00:00,  4.76s/it]\n",
      "100%|██████████| 490/490 [54:52<00:00,  6.72s/it]    \n"
     ]
    }
   ],
   "source": [
    "exp1 = exp_fn_wrap(test_x)\n",
    "exp2 = exp_fn_wrap(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./explanations/diabetes1.npy', exp1)\n",
    "np.save('./explanations/diabetes2.npy', exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = np.load('./explanations/diabetes1.npy')\n",
    "exp2 = np.load('./explanations/diabetes2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_exp(exp, feature_num):\n",
    "    enc_exp = np.zeros((len(exp),feature_num))\n",
    "    for i in range(len(exp)):\n",
    "        for j in range(len(exp[i])):\n",
    "            enc_exp[i][int(exp[i,j,0])] = exp[i,j,1]\n",
    "    return enc_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krish/anaconda3/envs/interpret/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py:984: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  self._check_params(X)\n"
     ]
    }
   ],
   "source": [
    "i = metrics.calc_identity(exp1, exp2)\n",
    "s = metrics.calc_separability(exp1)\n",
    "enc1 = enc_exp(exp1, len(X_test.columns))\n",
    "sb = metrics.calc_stability(enc1, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100.0, 0, 490), (0, 490, 240100, 0.0), (192, 490))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i, s, sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm = metrics.normalize_test(X_train, X_test_sample)\n",
    "sim = metrics.calc_similarity(exp1, X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3235792449368628"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/490 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490/490 [47:31<00:00,  5.82s/it]\n"
     ]
    }
   ],
   "source": [
    "list_monotonicity = []\n",
    "list_non_sensitivity = []\n",
    "list_effective_complexity = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(test_x))):\n",
    "    atr = exp1[i]\n",
    "    sorted_atr = [j for i,j in atr]\n",
    "    sorted_feat = [i for i,j in atr]\n",
    "    y = np.zeros(2, dtype=int)\n",
    "    np.put(y, test_y[i], 1)\n",
    "    example = metrics.FeatureAttribution(automl, test_x[i], y, sorted_atr)\n",
    "    list_monotonicity.append(example.monotonicity())\n",
    "    list_non_sensitivity.append(example.non_sensitivity())\n",
    "    list_effective_complexity.append(example.effective_complexity(sorted_feat, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017664565003795714\n",
      "8.944897959183674\n",
      "0.0\n",
      "0.0030237643705725574\n",
      "9.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(list_monotonicity))\n",
    "print(np.mean(list_non_sensitivity))\n",
    "print(np.mean(list_effective_complexity))\n",
    "\n",
    "print(np.median(list_monotonicity))\n",
    "print(np.median(list_non_sensitivity))\n",
    "print(np.median(list_effective_complexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490/490 [3:24:16<00:00, 25.01s/it]    \n"
     ]
    }
   ],
   "source": [
    "trust = metrics.calc_trust_score(automl, test_x, exp1, 3, X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21428571428571427"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 538.3214120864868 seconds ---\n",
      "--- 528.7014925479889 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from lime import submodular_pick\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "exp1 = submodular_pick.SubmodularPick(explainer, X_test_sample.values, automl.predict_proba, sample_size=200, num_features=len(X_test_sample.columns), num_exps_desired=5)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "exp2 = submodular_pick.SubmodularPick(explainer, X_test_sample.values, automl.predict_proba, sample_size=200, num_features=len(X_test_sample.columns), num_exps_desired=5)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./explanations/diabetes_lime_global1.pkl', 'wb') as f:\n",
    "    pickle.dump(exp1, f)\n",
    "\n",
    "with open('./explanations/diabetes_lime_global2.pkl', 'wb') as f:\n",
    "    pickle.dump(exp2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./explanations/diabetes_lime_global1.pkl', 'rb') as f:\n",
    "    exp1 = pickle.load(f)\n",
    "\n",
    "with open('./explanations/diabetes_lime_global2.pkl', 'rb') as f:\n",
    "    exp2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_imp(sp_obj):\n",
    "    W_pick=pd.DataFrame([dict(this.as_list(this.available_labels()[0])) for this in sp_obj.sp_explanations]).fillna(0)\n",
    "    W_pick['prediction'] = [this.available_labels()[0] for this in sp_obj.sp_explanations]\n",
    "    W=pd.DataFrame([dict(this.as_list(this.available_labels()[0])) for this in sp_obj.explanations]).fillna(0)\n",
    "    W['prediction'] = [this.available_labels()[0] for this in sp_obj.explanations]\n",
    "    np.abs(W.drop(\"prediction\", axis=1)).mean(axis=0).sort_values(ascending=False).head(25).sort_values(ascending=True)\n",
    "    grped_coeff = W.groupby(\"prediction\").mean()\n",
    "    grped_coeff = grped_coeff.T\n",
    "    return grped_coeff[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp1 = get_feature_imp(exp1)\n",
    "feat_imp2 = get_feature_imp(exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.94970596e-02,  3.90620310e-02,  2.32662770e-02,  1.40797886e-03,\n",
       "        2.52952134e-03, -1.23929943e-04, -2.95757066e-02, -8.71038688e-03,\n",
       "        8.27913931e-04, -5.38385658e-03,  9.35783612e-03, -1.84607045e-02,\n",
       "        1.02286008e-02, -2.47564839e-03,  1.88735530e-02, -1.36632873e-03,\n",
       "       -2.93947051e-03,  2.11718548e-03,  4.23474778e-03,  2.43861870e-04,\n",
       "        9.71351806e-04,  6.58040173e-05, -1.75528740e-04,  2.05163934e-03,\n",
       "       -4.69336464e-04, -2.01329118e-03,  1.64547431e-03, -1.23655440e-04,\n",
       "       -6.98920891e-04,  6.43259701e-04, -5.06287048e-04,  5.29642676e-04,\n",
       "        2.61169942e-03,  0.00000000e+00,  0.00000000e+00, -6.50211980e-04,\n",
       "       -6.58310208e-04,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -8.29703262e-02,  2.36990653e-02,  4.83198793e-03,\n",
       "       -6.85357902e-03, -3.85530412e-04,  8.01615595e-04, -1.09195502e-03,\n",
       "       -1.26165962e-04,  2.46400685e-03,  6.55483353e-04,  2.45783401e-05,\n",
       "        2.87016948e-04,  1.07288841e-03, -3.58220288e-02, -2.92076855e-02,\n",
       "        1.80234140e-02,  4.13747236e-03,  1.99540139e-03,  2.71718471e-04,\n",
       "        1.00240587e-03, -7.52720403e-03, -9.21865268e-04, -1.68188243e-04,\n",
       "        1.81083261e-02,  4.19153184e-03, -6.78273122e-06,  6.82234802e-02,\n",
       "        1.08518523e-02,  9.18694387e-04, -4.36430316e-03,  3.81473565e-04,\n",
       "       -4.22008508e-03, -5.91019738e-03,  5.30226041e-03, -8.12463893e-05,\n",
       "        4.81075545e-03, -3.61386004e-03,  1.90734063e-02, -8.51018035e-04,\n",
       "        7.65684710e-04,  1.29844358e-04, -3.84493705e-07, -6.26636520e-04,\n",
       "       -7.09027336e-05, -2.80163417e-04,  0.00000000e+00])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_identity(feat_imp1, feat_imp2):\n",
    "    sum = 0\n",
    "    for i in range(len(feat_imp1)):\n",
    "        if(feat_imp1[i] == feat_imp2[i]):\n",
    "            sum += 1\n",
    "    return sum/len(feat_imp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05747126436781609"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = global_identity(feat_imp1, feat_imp2)\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_fi(feat_imp):\n",
    "    return np.abs(feat_imp) / np.sum(np.abs(feat_imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_feat_imp = normal_fi(feat_imp1 + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entropy Ratio\n",
    "Ser = np.sum(normal_feat_imp*np.log(normal_feat_imp))/np.log(1/len(normal_feat_imp))\n",
    "\n",
    "# Kullback-Leibler Divergence\n",
    "Skl = np.sum(normal_feat_imp*np.log(normal_feat_imp/(1/len(normal_feat_imp))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gini(pfi):\n",
    "    sum = 0\n",
    "    for i in range(len(pfi)):\n",
    "        sum_curr = 0\n",
    "        for j in range(len(pfi)):\n",
    "            sum_curr += np.abs(pfi[i]-pfi[j])\n",
    "        sum += sum_curr\n",
    "    \n",
    "    return sum/(2*len(pfi)**2)*(np.sum(pfi)/len(pfi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sg = calc_gini(normal_feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7366600451611253, 1.176052042281062, 0.00010118636840223408)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ser, Skl, Sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_alpha_fi(normal_pfi, alpha):\n",
    "    j_inst = 0\n",
    "    sum = 0\n",
    "    for i in range(len(normal_pfi)-1, -1, -1):\n",
    "        sum += normal_pfi[i]\n",
    "        if sum<=alpha:\n",
    "            j_inst = i\n",
    "        else:\n",
    "            break\n",
    "    return 1- (j_inst/len(normal_pfi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9195402298850575"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_alpha_fi(normal_feat_imp, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_imp_all(sp_obj):\n",
    "    W_pick=pd.DataFrame([dict(this.as_list(this.available_labels()[0])) for this in sp_obj.sp_explanations]).fillna(0)\n",
    "    W_pick['prediction'] = [this.available_labels()[0] for this in sp_obj.sp_explanations]\n",
    "    W=pd.DataFrame([dict(this.as_list(this.available_labels()[0])) for this in sp_obj.explanations]).fillna(0)\n",
    "    W['prediction'] = [this.available_labels()[0] for this in sp_obj.explanations]\n",
    "    np.abs(W.drop(\"prediction\", axis=1)).mean(axis=0).sort_values(ascending=False).head(25).sort_values(ascending=True)\n",
    "    grped_coeff = W.groupby(\"prediction\").mean()\n",
    "    grped_coeff = grped_coeff.T\n",
    "    return grped_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_feat_imp, class2_feat_imp = get_feature_imp_all(exp1)[0].values, get_feature_imp_all(exp1)[1].values\n",
    "normal_class1_fi, normal_class2_fi = normal_fi(class1_feat_imp), normal_fi(class2_feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1874718408534028"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(normal_class1_fi - normal_class2_fi, ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_limits_and_names(idxs):\n",
    "    data = {}\n",
    "    for idx in idxs:\n",
    "        \n",
    "        data[idx] = {}\n",
    "        col_name = \"\"\n",
    "        for col in X_train.columns:\n",
    "            if str(col) in idx:\n",
    "                col_name = col\n",
    "                break\n",
    "        data[idx]['col_name'] = col_name\n",
    "        \n",
    "        split_lt = idx.split(\"<=\")\n",
    "        if len(split_lt) > 1:\n",
    "            for i in range(len(split_lt)):\n",
    "                split_lt[i] = split_lt[i].strip()\n",
    "                try:\n",
    "                    split_lt[i] = float(split_lt[i])\n",
    "                    data[idx]['upper'] = split_lt[i]\n",
    "                except:\n",
    "                    pass\n",
    "            split_lt2 = split_lt[0].split(\"<\")\n",
    "            if len(split_lt2) > 1:\n",
    "                for i in range(len(split_lt2)):\n",
    "                    split_lt2[i] = split_lt2[i].strip()\n",
    "                    try:\n",
    "                        split_lt2[i] = float(split_lt2[i])\n",
    "                        data[idx]['lower'] = split_lt2[i]\n",
    "                    except:\n",
    "                        pass\n",
    "        split_gt = idx.split(\">\")\n",
    "        if len(split_gt) > 1:\n",
    "            for i in range(len(split_gt)):\n",
    "                split_gt[i] = split_gt[i].strip()\n",
    "                try:\n",
    "                    split_gt[i] = float(split_gt[i])\n",
    "                    data[idx]['lower'] = split_gt[i]\n",
    "                except:\n",
    "                    pass\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46368754398311435\n"
     ]
    }
   ],
   "source": [
    "mean_correctness = 0\n",
    "feat_scores = get_feature_imp_all(exp1)\n",
    "feat_scores_index = feat_scores.index.tolist()\n",
    "exp_feature_name = get_limits_and_names(feat_scores_index)\n",
    "for i in range(len(X_test_sample)):\n",
    "    correctness = 0\n",
    "    for j in range(len(feat_scores_index)):\n",
    "        inst = 1\n",
    "        if exp_feature_name[feat_scores_index[j]]['col_name']:\n",
    "            if 'upper' in exp_feature_name[feat_scores_index[j]].keys():\n",
    "                if X_test_sample.iloc[i][exp_feature_name[feat_scores_index[j]]['col_name']] > exp_feature_name[feat_scores_index[j]]['upper']:\n",
    "                    inst = 0\n",
    "            if 'lower' in exp_feature_name[feat_scores_index[j]].keys():\n",
    "                if X_test_sample.iloc[i][exp_feature_name[feat_scores_index[j]]['col_name']] <= exp_feature_name[feat_scores_index[j]]['lower']:\n",
    "                    inst = 0\n",
    "                    \n",
    "        # print(inst, feat_scores.iloc[j][y_test.iloc[i]], feat_scores_index[j], exp_feature_name[feat_scores_index[j]]['col_name'], X_test_sample.iloc[i][exp_feature_name[feat_scores_index[j]]['col_name']])\n",
    "        correctness += inst * 1\n",
    "    if correctness < 0:\n",
    "        correctness = 0\n",
    "    mean_correctness += correctness/len(feat_scores_index)\n",
    "print(mean_correctness/len(X_test_sample))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ciu import determine_ciu\n",
    "import tqdm\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_exp(exp, feature_num):\n",
    "    enc_exp = np.zeros((len(exp),feature_num))\n",
    "    for i in range(len(exp)):\n",
    "        for j in range(len(exp[i])):\n",
    "            enc_exp[i][int(exp[i,j,0])] = exp[i,j,1]\n",
    "    return enc_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_fn_blk(xtest):\n",
    "    exp1 = []\n",
    "    for i in tqdm.tqdm(range(len(xtest))):\n",
    "        exp = determine_ciu(X_test.iloc[i:i+1], automl.predict_proba, X_train.to_dict('list'), samples = 1000, prediction_index = 1)\n",
    "        exp_list = [[feat_list.index(i), exp.ci[i]] for i in exp.ci]\n",
    "        exp1.append(exp_list)\n",
    "    return np.array(exp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490/490 [44:05<00:00,  5.40s/it]\n",
      "100%|██████████| 490/490 [42:35<00:00,  5.21s/it]\n"
     ]
    }
   ],
   "source": [
    "exp1 = exp_fn_blk(X_test_sample)\n",
    "exp2 = exp_fn_blk(X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./explanations/diabetes_ciu1.npy', exp1)\n",
    "np.save('./explanations/diabetes_ciu2.npy', exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = np.load('./explanations/hiv_ciu1.npy')\n",
    "exp2 = np.load('./explanations/hiv_ciu2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krish/anaconda3/envs/interpret/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py:984: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  self._check_params(X)\n"
     ]
    }
   ],
   "source": [
    "i = metrics.calc_identity(exp1, exp2)\n",
    "s = metrics.calc_separability(exp1)\n",
    "enc1 = enc_exp(exp1, len(feat_list))\n",
    "sb = metrics.calc_stability(enc1, y_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100.0, 0, 490), (0, 490, 240100, 0.0), (233, 490))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i, s, sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm = metrics.normalize_test(X_train, X_test_sample)\n",
    "sim = metrics.calc_similarity(exp1, X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5912382359091071"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490/490 [54:35<00:00,  6.69s/it]  \n"
     ]
    }
   ],
   "source": [
    "list_monotonicity = []\n",
    "list_non_sensitivity = []\n",
    "list_effective_complexity = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(X_test_sample))):\n",
    "    atr = exp1[i]\n",
    "    sorted_atr = [j for i,j in atr]\n",
    "    sorted_feat = [i for i,j in atr]\n",
    "    y = np.zeros(2, dtype=int)\n",
    "    np.put(y, y_test_sample.iloc[i], 1)\n",
    "    example = metrics.FeatureAttribution(automl, X_test_sample.to_numpy()[i], y, sorted_atr)\n",
    "    list_monotonicity.append(example.monotonicity())\n",
    "    list_non_sensitivity.append(example.non_sensitivity())\n",
    "    list_effective_complexity.append(example.effective_complexity(sorted_feat, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015983156317531437\n",
      "5.995918367346939\n",
      "0.05714285714285714\n",
      "0.010337947072485944\n",
      "6.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(list_monotonicity))\n",
    "print(np.mean(list_non_sensitivity))\n",
    "print(np.mean(list_effective_complexity))\n",
    "\n",
    "print(np.median(list_monotonicity))\n",
    "print(np.median(list_non_sensitivity))\n",
    "print(np.median(list_effective_complexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490/490 [2:39:54<00:00, 19.58s/it]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.27755102040816326"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.calc_trust_score(automl, X_test_sample.to_numpy(), exp1, 3, X_train.columns.to_list())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RULEFIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrules import SkopeRules\n",
    "import metrics_rules\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SkopeRules(max_depth_duplication=2,\n",
    "                    n_estimators=512,\n",
    "                    precision_min=0.3,\n",
    "                    recall_min=0.1,\n",
    "                    feature_names=X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 106.79994249343872 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.03854656219482422 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "top_rules1 = clf.score_top_rules(X_test_sample)\n",
    "top_rules2 = clf.score_top_rules(X_test_sample)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 490, 490)\n",
      "(76788, 490, 240100, 31.98167430237401)\n",
      "(225, 490)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krish/anaconda3/envs/interpret/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py:984: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  self._check_params(X)\n"
     ]
    }
   ],
   "source": [
    "i = metrics_rules.calc_identity_rules(top_rules1, top_rules2)\n",
    "print(i)\n",
    "\n",
    "s = metrics_rules.calc_separability_rules(top_rules1)\n",
    "print(s)\n",
    "\n",
    "enc_rules = metrics_rules.exp_enc(clf, top_rules1)\n",
    "sb = metrics_rules.calc_stability_rules(enc_rules, y_test_sample)\n",
    "print(sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9298346247582785\n"
     ]
    }
   ],
   "source": [
    "X_test_norm = metrics_rules.normalize_test(X_train, X_test_sample)\n",
    "sim = metrics_rules.calc_similarity(enc_rules, X_test_norm)\n",
    "print(sim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RULEMATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = X_train.columns.tolist()\n",
    "continuous_features = X_train.columns.drop(categorical_features).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rulematrix\n",
    "import time\n",
    "import metrics_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_continuous = [True if i in continuous_features else False for i in X_train.columns.tolist()]\n",
    "is_categorical = [True if i in categorical_features else False for i in X_train.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = rulematrix.surrogate.rule_surrogate(\n",
    "    automl.predict,\n",
    "    X_train,\n",
    "    sampling_rate=4,\n",
    "    is_continuous=is_continuous,\n",
    "    is_categorical=is_categorical,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = X_test_sample.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_fn_blk(xtest):\n",
    "    exp1 = []\n",
    "    for i in range(len(xtest)):\n",
    "        queried_rules = np.arange(surrogate.student.n_rules)[surrogate.student.decision_path(test_x[i].reshape(1,-1)).reshape(-1)]\n",
    "        exp1.append(queried_rules[-1])\n",
    "    return np.array(exp1)\n",
    "exp_fn_wrap = lambda x: np.array(exp_fn_blk(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.5698792934417725 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "exp1 = exp_fn_blk(test_x)\n",
    "exp2 = exp_fn_blk(test_x)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_exp(exp, n_features):\n",
    "    enc = []\n",
    "    for i in range(exp.shape[0]):\n",
    "        new = np.zeros(n_features)\n",
    "        for j in surrogate.student.rule_list[exp[i]].clauses:\n",
    "            new[j.feature_idx] = 1\n",
    "        enc.append(new)\n",
    "    return np.array(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_exp = enc_exp(exp1, X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 490, 490)\n",
      "(13066, 490, 240100, 5.441899208663057)\n",
      "(197, 490)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krish/anaconda3/envs/interpret/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py:984: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  self._check_params(X)\n"
     ]
    }
   ],
   "source": [
    "i = metrics_rules.calc_identity_rules(exp1, exp2)\n",
    "print(i)\n",
    "\n",
    "s = metrics_rules.calc_separability_rules(exp1)\n",
    "print(s)\n",
    "\n",
    "sb = metrics_rules.calc_stability_rules(enc_exp, y_test_sample)\n",
    "print(sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm = metrics_rules.normalize_test(X_train, X_test_sample)\n",
    "sim = metrics_rules.calc_similarity(enc_exp, X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7731358947906135"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANCHOR Global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anchor import anchor_tabular\n",
    "import anchor_utils\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "    y_train.unique().tolist(),\n",
    "    X_train.columns.tolist(),\n",
    "    X_train.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance using Anchor\n",
    "def calc_fi(X_test, model, explainer):\n",
    "    all_exps = []\n",
    "    for i in tqdm.tqdm(range(len(X_test))):\n",
    "        exp = explainer.explain_instance(X_test.values[i], model.predict, threshold=0.95)\n",
    "        all_exps.append(exp.exp_map)\n",
    "    fi = anchor_utils.greedy_pick_anchor(all_exps, X_test.values, k = len(X_test.columns))\n",
    "    return fi\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490/490 [2:14:32<00:00, 16.48s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.08571428571428572\n",
      "1 0.15918367346938775\n",
      "2 0.22857142857142856\n",
      "3 0.2938775510204082\n",
      "4 0.33877551020408164\n",
      "5 0.3836734693877551\n",
      "6 0.41836734693877553\n",
      "7 0.4530612244897959\n",
      "8 0.4816326530612245\n",
      "9 0.5081632653061224\n",
      "10 0.5285714285714286\n",
      "11 0.5428571428571428\n",
      "12 0.5530612244897959\n",
      "13 0.563265306122449\n",
      "14 0.573469387755102\n",
      "15 0.5836734693877551\n",
      "16 0.5918367346938775\n",
      "17 0.6\n",
      "18 0.6081632653061224\n",
      "19 0.6163265306122448\n",
      "20 0.6224489795918368\n",
      "21 0.6285714285714286\n",
      "22 0.6346938775510204\n",
      "23 0.6408163265306123\n",
      "24 0.6469387755102041\n",
      "25 0.6530612244897959\n",
      "26 0.6571428571428571\n",
      "27 0.6612244897959184\n",
      "28 0.6653061224489796\n",
      "29 0.6693877551020408\n",
      "30 0.673469387755102\n",
      "31 0.6775510204081633\n",
      "32 0.6816326530612244\n",
      "33 0.6857142857142857\n",
      "34 0.689795918367347\n",
      "35 0.6938775510204082\n",
      "36 0.6979591836734694\n",
      "37 0.7020408163265306\n",
      "38 0.7061224489795919\n",
      "39 0.7081632653061225\n",
      "40 0.710204081632653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490/490 [2:15:39<00:00, 16.61s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.30612244897959184\n",
      "1 0.40816326530612246\n",
      "2 0.4775510204081633\n",
      "3 0.5163265306122449\n",
      "4 0.5510204081632653\n",
      "5 0.573469387755102\n",
      "6 0.5938775510204082\n",
      "7 0.6122448979591837\n",
      "8 0.6306122448979592\n",
      "9 0.6489795918367347\n",
      "10 0.6591836734693878\n",
      "11 0.6693877551020408\n",
      "12 0.6775510204081633\n",
      "13 0.6857142857142857\n",
      "14 0.6938775510204082\n",
      "15 0.7020408163265306\n",
      "16 0.7081632653061225\n",
      "17 0.7142857142857143\n",
      "18 0.7204081632653061\n",
      "19 0.726530612244898\n",
      "20 0.7326530612244898\n",
      "21 0.7387755102040816\n",
      "22 0.7428571428571429\n",
      "23 0.746938775510204\n",
      "24 0.7510204081632653\n",
      "25 0.7551020408163265\n",
      "26 0.7591836734693878\n",
      "27 0.763265306122449\n",
      "28 0.7673469387755102\n",
      "29 0.7714285714285715\n",
      "30 0.7755102040816326\n",
      "31 0.7795918367346939\n",
      "32 0.7816326530612245\n",
      "33 0.7836734693877551\n",
      "34 0.7857142857142857\n",
      "35 0.7877551020408163\n",
      "36 0.789795918367347\n",
      "37 0.7918367346938775\n",
      "38 0.7938775510204081\n",
      "39 0.7959183673469388\n",
      "40 0.7979591836734694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exp1 = calc_fi(X_test_sample, automl, explainer)\n",
    "exp2 = calc_fi(X_test_sample, automl, explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./explanations/diabtetes_anc_global1.pkl', 'wb') as f:\n",
    "    pickle.dump(exp1, f)\n",
    "\n",
    "with open('./explanations/diabtetes_anc_global2.pkl', 'wb') as f:\n",
    "    pickle.dump(exp2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./explanations/diabtetes_anc_global1.pkl', 'rb') as f:\n",
    "    exp1 = pickle.load(f)\n",
    "\n",
    "with open('./explanations/diabtetes_anc_global2.pkl', 'rb') as f:\n",
    "    exp2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 228/228 [1:09:03<00:00, 18.17s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.09210526315789473\n",
      "1 0.15789473684210525\n",
      "2 0.20175438596491227\n",
      "3 0.2412280701754386\n",
      "4 0.27631578947368424\n",
      "5 0.30701754385964913\n",
      "6 0.33771929824561403\n",
      "7 0.36403508771929827\n",
      "8 0.38596491228070173\n",
      "9 0.40789473684210525\n",
      "10 0.4298245614035088\n",
      "11 0.4473684210526316\n",
      "12 0.4649122807017544\n",
      "13 0.4780701754385965\n",
      "14 0.49122807017543857\n",
      "15 0.5043859649122807\n",
      "16 0.5175438596491229\n",
      "17 0.5263157894736842\n",
      "18 0.5350877192982456\n",
      "19 0.543859649122807\n",
      "20 0.5526315789473685\n",
      "21 0.5614035087719298\n",
      "22 0.5701754385964912\n",
      "23 0.5789473684210527\n",
      "24 0.5833333333333334\n",
      "25 0.5877192982456141\n",
      "26 0.5921052631578947\n",
      "27 0.5964912280701754\n",
      "28 0.6008771929824561\n",
      "29 0.6052631578947368\n",
      "30 0.6096491228070176\n",
      "31 0.6140350877192983\n",
      "32 0.618421052631579\n",
      "33 0.6228070175438597\n",
      "34 0.6271929824561403\n",
      "35 0.631578947368421\n",
      "36 0.6359649122807017\n",
      "37 0.6403508771929824\n",
      "38 0.6447368421052632\n",
      "39 0.6491228070175439\n",
      "40 0.6535087719298246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 262/262 [1:03:13<00:00, 14.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3511450381679389\n",
      "1 0.4122137404580153\n",
      "2 0.4618320610687023\n",
      "3 0.5\n",
      "4 0.5343511450381679\n",
      "5 0.5648854961832062\n",
      "6 0.5954198473282443\n",
      "7 0.6145038167938931\n",
      "8 0.6335877862595419\n",
      "9 0.6526717557251909\n",
      "10 0.6679389312977099\n",
      "11 0.6793893129770993\n",
      "12 0.6908396946564885\n",
      "13 0.7022900763358778\n",
      "14 0.7099236641221374\n",
      "15 0.7175572519083969\n",
      "16 0.7251908396946565\n",
      "17 0.732824427480916\n",
      "18 0.7404580152671756\n",
      "19 0.7480916030534351\n",
      "20 0.7557251908396947\n",
      "21 0.7595419847328244\n",
      "22 0.7633587786259542\n",
      "23 0.767175572519084\n",
      "24 0.7709923664122137\n",
      "25 0.7748091603053435\n",
      "26 0.7786259541984732\n",
      "27 0.7824427480916031\n",
      "28 0.7862595419847328\n",
      "29 0.7900763358778626\n",
      "30 0.7938931297709924\n",
      "31 0.7977099236641222\n",
      "32 0.8015267175572519\n",
      "33 0.8053435114503816\n",
      "34 0.8091603053435115\n",
      "35 0.8129770992366412\n",
      "36 0.816793893129771\n",
      "37 0.8206106870229007\n",
      "38 0.8244274809160306\n",
      "39 0.8282442748091603\n",
      "40 0.8320610687022901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_sample_0 = X_test_sample[y_test_sample==0]\n",
    "X_test_sample_1 = X_test_sample[y_test_sample==1]\n",
    "\n",
    "exp_0 = calc_fi(X_test_sample_0, automl, explainer)\n",
    "exp_1 = calc_fi(X_test_sample_1, automl, explainer)\n",
    "\n",
    "with open('./explanations/diabtetes_anc_global_class0.pkl', 'wb') as f:\n",
    "    pickle.dump(exp_0, f)\n",
    "\n",
    "with open('./explanations/diabtetes_anc_global_class1.pkl', 'wb') as f:\n",
    "    pickle.dump(exp_1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./explanations/diabtetes_anc_global_class0.pkl', 'rb') as f:\n",
    "    exp_0 = pickle.load(f)\n",
    "\n",
    "with open('./explanations/diabtetes_anc_global_class1.pkl', 'rb') as f:\n",
    "    exp_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_fi(feat_imp):\n",
    "    feat_imp = np.array(feat_imp) + 1e-9\n",
    "    return np.abs(feat_imp) / np.sum(np.abs(feat_imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_feat_imp1 = normal_fi(exp1)\n",
    "normal_feat_imp2 = normal_fi(exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def global_identity(feat_imp1, feat_imp2):\n",
    "    sum = 0\n",
    "    for i in range(len(feat_imp1)):\n",
    "        if(feat_imp1[i] == feat_imp2[i]):\n",
    "            sum += 1\n",
    "    return sum/len(feat_imp1)\n",
    "\n",
    "i = global_identity(normal_feat_imp1, normal_feat_imp2)\n",
    "i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entropy Ratio\n",
    "Ser = np.sum(normal_feat_imp1*np.log(normal_feat_imp1))/np.log(1/len(normal_feat_imp1))\n",
    "\n",
    "# Kullback-Leibler Divergence\n",
    "Skl = np.sum(normal_feat_imp1*np.log(normal_feat_imp1/(1/len(normal_feat_imp1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gini(pfi):\n",
    "    sum = 0\n",
    "    for i in range(len(pfi)):\n",
    "        sum_curr = 0\n",
    "        for j in range(len(pfi)):\n",
    "            sum_curr += np.abs(pfi[i]-pfi[j])\n",
    "        sum += sum_curr\n",
    "    \n",
    "    return sum/(2*len(pfi)**2)*(np.sum(pfi)/len(pfi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sg = calc_gini(normal_feat_imp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8835989740993055, 0.4322635983205434, 0.00030108661614839223)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ser, Skl, Sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_alpha_fi(normal_pfi, alpha):\n",
    "    j_inst = 0\n",
    "    sum = 0\n",
    "    for i in range(len(normal_pfi)-1, -1, -1):\n",
    "        sum += normal_pfi[i]\n",
    "        if sum<=alpha:\n",
    "            j_inst = i\n",
    "        else:\n",
    "            break\n",
    "    return 1- (j_inst/len(normal_pfi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7804878048780488"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_alpha_fi(normal_feat_imp1, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20889363011664128"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(normal_fi(exp_0) - normal_fi(exp_1), ord=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
